{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Immersion Day \n",
    "\n",
    "# What Are We Doing Here?\n",
    "\n",
    "We're going to make a [factorisation machine](https://sagemaker.readthedocs.io/en/stable/factorization_machines.html) that will act as a binary recommender (like vs don't like) against data from [movielens](https://movielens.org).\n",
    "\n",
    "This is based on a [blog post](https://medium.com/@julsimon/building-a-movie-recommender-with-factorization-machines-on-amazon-sagemaker-cedbfc8c93d8).\n",
    "\n",
    "\n",
    "To get there, we'll do the following:\n",
    "\n",
    "##### A. Data Preparation\n",
    "1. Import dependencies\n",
    "2. Download the movielens data set - this contains movies and ratings\n",
    "3. Create separate training and test data sets from what we've downloaded\n",
    "4. Shuffle this data (to aid with training)\n",
    "\n",
    "##### B. Data Preparation\n",
    "5. Create a one-hot encoded sparse matrix of features & labels\n",
    "6. Serialize in ProtoBuf format (a requirement of the factorisation machine Estimator in SageMaker)\n",
    "\n",
    "##### C. Train & Deploy the Model\n",
    "7. Create a factorisation machine and configure it's hyperparameters (non-learnt parameters)\n",
    "8. Train the model by calling `fit()`\n",
    "9. Deploy a SageMaker endpoint with `deploy()`\n",
    "10. Configure serialization options for the predictor\n",
    "\n",
    "##### D. Test Inference\n",
    "11. Call the predictor\n",
    "\n",
    "\n",
    "\n",
    "# A. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Import Dependencies\n",
    "* Import the dependencies we need\n",
    "* Configure the S3 bucket name we'll use\n",
    "\n",
    "*Don't forget to change the your_initials value to the initials you used in Lab1*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_initials = 'pmj'\n",
    "bucket_name = your_initials + '-ml-id-lab'\n",
    "\n",
    "import sagemaker\n",
    "import sagemaker.amazon.common as smac\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.predictor import json_deserializer\n",
    "  \n",
    "import boto3, csv, io, json\n",
    "import numpy as np\n",
    "from scipy.sparse import lil_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> While the code is running, there will be a bracketed asterisk showing to the left of the code **[*]**. Once finished, the asterisk will be replaced with a number showing the order of execution within the current notebook document's state.\n",
    "\n",
    "Next, download one of the data files used in Lab1 to the notebook. \n",
    "\n",
    "## 2. Download the movielens data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "s3.Bucket(bucket_name).download_file('movielens-data/u.data/data.csv', 'u.data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file downloaded is a compacted version if the data explored in Lab1. This is the description of the file:\n",
    "\n",
    "> ```text\n",
    "> u.data \n",
    ">\n",
    "> The full u data set, 100000 ratings by 943 users on 1682 items.\n",
    "> Each user has rated at least 20 movies.  Users and items are numbered consecutively from 1.\n",
    "The data is randomly ordered. This is a tab separated list of:\n",
    "> user id | item id | rating | timestamp\n",
    "> The time stamps are unix seconds since 1/1/1970 UTC```\n",
    "\n",
    "While this is an intuitive and realtively compact way of storing the information, it is not optimal for training factorisation machine models. In order to have good training data, this data needs to be split and transformed.\n",
    "\n",
    "First, split the data into one larger training part and one smaller testing part (10 samples per user).\n",
    "\n",
    "At the end of running the code, the two rating counters will be printed to an output that is added below the cell. \n",
    "\n",
    "## 3. Create separate training and test data sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbUsers = 943\n",
    "nbMovies = 1682\n",
    "nbFeatures = nbUsers+nbMovies\n",
    "# Pick 10 ratings _per user_ and save as test data (to \"ua.test\")\n",
    "# Save the rest as training data set (to \"ua.base\")\n",
    "maxRatingsByUser = 10\n",
    "\n",
    "def getStringUserId(userId):\n",
    "    return str(int(userId)-1)\n",
    "\n",
    "\n",
    "def initialiseTestRatings():\n",
    "    # Since we only want a maximum of 10, we want to keep track of the number of ratings per user as we build our datasets\n",
    "    # Create a dictionary, and initialise the count for each userId to 0\n",
    "    testRatingsByUser = {}\n",
    "    for userId in range(nbUsers):\n",
    "        testRatingsByUser[str(userId)] = 0\n",
    "    return testRatingsByUser\n",
    "\n",
    "def initialiseFiles():\n",
    "\n",
    "    # IPython allows us to use ! to execute shell commands\n",
    "    # Clean any existing 'base' and 'test' files\n",
    "    !rm -f ua.base || touch ua.base\n",
    "    !rm -f ua.test || touch ua.test\n",
    "\n",
    "    testRatingsByUser = initialiseTestRatings()\n",
    "\n",
    "    # Obtain file handle to the main data file (read access)\n",
    "    # Obtain file handles to the desired \"base\" and \"test\" files we just initialised (write access)\n",
    "    with open('u.data', 'r') as data_file, open('ua.base', 'w') as uabase_file, open('ua.test', 'w') as uatest_file:\n",
    "\n",
    "        # Use tabs as delimiters\n",
    "        filedata_reader = csv.reader(data_file, delimiter='\\t')\n",
    "        uabase_writer = csv.writer(uabase_file, delimiter='\\t')\n",
    "        uatest_writer = csv.writer(uatest_file, delimiter='\\t')\n",
    "\n",
    "        # skip headers\n",
    "        next(filedata_reader, None)\n",
    "\n",
    "        # Initialise counters\n",
    "        nbRatingsTrain = 0\n",
    "        nbRatingsTest = 0\n",
    "\n",
    "        # For every rating line in file\n",
    "        for userId, movieId, rating, timestamp in filedata_reader:\n",
    "\n",
    "            # If we've within the max ratings per user limit, keep the record as test data\n",
    "            if testRatingsByUser[getStringUserId(userId)] < maxRatingsByUser:\n",
    "                uatest_writer.writerow([userId, movieId, rating, timestamp])\n",
    "                testRatingsByUser[getStringUserId(\n",
    "                    userId)] = testRatingsByUser[getStringUserId(userId)] + 1\n",
    "                nbRatingsTest = nbRatingsTest+1\n",
    "\n",
    "            # If we've already got enough test data for the user in question, use for training\n",
    "            else:\n",
    "                uabase_writer.writerow([userId, movieId, rating, timestamp])\n",
    "                nbRatingsTrain = nbRatingsTrain+1\n",
    "                \n",
    "    return nbRatingsTrain, nbRatingsTest\n",
    "\n",
    "\n",
    "configure()\n",
    "nbRatingsTrain, nbRatingsTest = initialiseFiles()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Check the newly partitioned data\n",
    "Make sure the partitioned data looks good by printing the first 10 rows of each file. \n",
    "> Notice that the exclamation mark starting each line in this snippets means that the line is to be executed as a shell command, rather than as python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAINING DATA:\n",
      "userId\tmovieId\trating\ttimestamp\n",
      "13\t498\t4\t882139901\n",
      "13\t892\t3\t882774224\n",
      "13\t229\t4\t882397650\n",
      "181\t741\t1\t878962918\n",
      "181\t1015\t1\t878963121\n",
      "13\t864\t4\t882141924\n",
      "222\t812\t2\t881059117\n",
      "269\t234\t1\t891449406\n",
      "13\t901\t1\t883670672\n",
      "276\t70\t4\t874790826\n",
      "\n",
      "TESTING DATA:\n",
      "userId\tmovieId\trating\ttimestamp\n",
      "196\t242\t3\t881250949\n",
      "186\t302\t3\t891717742\n",
      "22\t377\t1\t878887116\n",
      "244\t51\t2\t880606923\n",
      "166\t346\t1\t886397596\n",
      "298\t474\t4\t884182806\n",
      "115\t265\t2\t881171488\n",
      "253\t465\t5\t891628467\n",
      "305\t451\t3\t886324817\n",
      "6\t86\t3\t883603013\n",
      "\n",
      "TRAINING DATA (COUNT)\n",
      "90570 ua.base\n",
      "\n",
      "TEST DATA (COUNT)\n",
      "9430 ua.test\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!echo\n",
    "!echo \"TRAINING DATA:\"\n",
    "!echo -e \"userId\\tmovieId\\trating\\ttimestamp\"\n",
    "!head -10 ua.base\n",
    "!echo\n",
    "!echo \"TESTING DATA:\"\n",
    "!echo -e \"userId\\tmovieId\\trating\\ttimestamp\"\n",
    "!head -10 ua.test\n",
    "!echo\n",
    "!echo \"TRAINING DATA (COUNT)\"\n",
    "!wc -l ua.base\n",
    "!echo\n",
    "!echo \"TEST DATA (COUNT)\"\n",
    "!wc -l ua.test\n",
    "!echo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should show ten lines containing four columns for each file. You may notice that the training data seems to have reoccuring lines contains the same value in the first column (user_id). **These types of regularities in the training data can lead to suboptimal training**.\n",
    "\n",
    "## 4. Shuffle this data (to aid with training)\n",
    "Create a new file containing shuffled training data.\n",
    "\n",
    "> If you're intrigued, `shuf` is available through `coreutils` on the Mac, but not installed by default.\n",
    "> `brew install coreutils` to get it.\n",
    "\n",
    "### 4.1 Check the newly shuffled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\t126\t3\t883697293\r",
      "\r\n",
      "624\t100\t5\t879792581\r",
      "\r\n",
      "429\t1425\t3\t882387633\r",
      "\r\n",
      "915\t347\t5\t891031477\r",
      "\r\n",
      "642\t1000\t3\t885602340\r",
      "\r\n",
      "640\t1054\t1\t886474010\r",
      "\r\n",
      "371\t73\t5\t880435397\r",
      "\r\n",
      "38\t409\t5\t892433135\r",
      "\r\n",
      "286\t117\t2\t876521650\r",
      "\r\n",
      "843\t566\t3\t879444766\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!shuf ua.base -o ua.base.shuffled\n",
    "!head -10 ua.base.shuffled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, we now have some test and training data.\n",
    "\n",
    "# B. Data preparation\n",
    "\n",
    "Now that we have our files, we need to get them into a format that SageMaker expects.\n",
    "\n",
    "1. We create a one-hot encoded sparse matrix\n",
    "2. We serialise this matrix as ProtoBuf\n",
    "\n",
    "## 5. Create a one-hot encoded sparse matrix of features & labels\n",
    "\n",
    "You now have two sets of source data, but need to process them more before training and testing a factorization machine model. What is needed for each of the sets is:\n",
    "\n",
    "- Create a one-hot encoded sparse matrix holding **features** (the input to the model)\n",
    "- Create a **label** array (the expected output from the model)\n",
    "- Serialize both of the above into protobuf format and write them to the S3 bucket.\n",
    "\n",
    "If you've not come across the term before (I hadn't), [one-hot](https://en.wikipedia.org/wiki/One-hot) indicates that only a single bit is flipped - e.g. 010000:\n",
    "\n",
    "> In digital circuits and machine learning, one-hot is a group of bits among which the legal combinations of values are only those with a single high (1) bit and all the others low (0).\n",
    "\n",
    "This is a [sparse matrix](https://en.wikipedia.org/wiki/Sparse_matrix) by nature:\n",
    "\n",
    "> In numerical analysis and computer science, a sparse matrix or sparse array is a matrix in which most of the elements are zero.\n",
    "\n",
    "We'll define `loadDataset()` (that loads a dataset and returns a one-hot encoded feature sparse matrix and a label vector. To do so we we use [`lil_matrix`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.lil_matrix.html) which constructs a:\n",
    "\n",
    "> Row-based linked list sparse matrix. This is a structure for constructing sparse matrices incrementally. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataset(filename, lines, columns):\n",
    "\n",
    "    # Features are one-hot encoded in a sparse matrix\n",
    "    features = lil_matrix((lines, columns)).astype('float32')\n",
    "\n",
    "    # Labels are stored in a vector\n",
    "    labels = []\n",
    "\n",
    "    lineNumber = 0\n",
    "    with open(filename, 'r') as file:\n",
    "\n",
    "        samples = csv.reader(file, delimiter='\\t')\n",
    "\n",
    "        for userId, movieId, rating, timestamp in samples:\n",
    "\n",
    "            # Flip the bit for the co-ordinates of the line number & userId\n",
    "            features[lineNumber, int(userId) - 1] = 1\n",
    "\n",
    "            # Also flip the bit for the co-ordinates of the movieId\n",
    "            # We effectively use a second vector after the first,\n",
    "            # offset by the number of users.\n",
    "            features[lineNumber, int(nbUsers) + int(movieId) - 1] = 1\n",
    "\n",
    "            # If it's a 4-5 star movie, we append 1 to the label set\n",
    "            # Recall that we are making a binary recommender (like/dislike)\n",
    "            if int(rating) >= 4:\n",
    "                labels.append(1)\n",
    "            else:\n",
    "                labels.append(0)\n",
    "\n",
    "            lineNumber = lineNumber + 1\n",
    "\n",
    "    return features, np.array(labels).astype('float32')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Verify the Sparse Matrixes we've created\n",
    "\n",
    "#### 5.1.1 The Training Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Shape: (90570, 2625)\n",
      "Labels Shape: (90570,)\n",
      "Training labels: 49906 ones, 40664 zeros\n"
     ]
    }
   ],
   "source": [
    "def checkDataSet(features, labels, nbRatings, nbFeatures):\n",
    "\n",
    "    print(\"Features Shape:\", features.shape)\n",
    "    print(\"Labels Shape:\", labels.shape)\n",
    "\n",
    "    assert features.shape == (nbRatings, nbFeatures)\n",
    "    assert labels.shape == (nbRatings, )\n",
    "\n",
    "    nonzero_labels = np.count_nonzero(labels)\n",
    "\n",
    "    print(\"Training labels: %d ones, %d zeros\" %\n",
    "          (nonzero_labels, nbRatings-nonzero_labels))\n",
    "\n",
    "train_features, train_labels = loadDataset('ua.base.shuffled', nbRatingsTrain, nbFeatures)\n",
    "checkDataSet(train_features, train_labels, nbRatingsTrain, nbFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.2 The Test Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Shape: (9430, 2625)\n",
      "Labels Shape: (9430,)\n",
      "Training labels: 5469 ones, 3961 zeros\n"
     ]
    }
   ],
   "source": [
    "test_features, test_labels = loadDataset('ua.test', nbRatingsTest, nbFeatures)\n",
    "checkDataSet(test_features, test_labels, nbRatingsTest, nbFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Serialize in ProtoBuf format\n",
    "Now, you will serialise these structures in [protobuf](https://developers.google.com/protocol-buffers/) format on S3. Start by defining target names for the S3 objects, and a function to do the serialisation and return the path to the object on S3.\n",
    "\n",
    "We use the [SageMaker API](https://aws.amazon.com/blogs/machine-learning/introduction-to-the-amazon-sagemaker-neural-topic-model/) to transform our sparse matrix. `write_spmatrix_to_sparse_tensor()` will:\n",
    "\n",
    "> convert scipy sparse matrix into RecordIO Protobuf format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'sagemaker/recommender-fm'\n",
    "\n",
    "train_key = 'train.protobuf'\n",
    "train_prefix = '{}/{}'.format(prefix, 'train')\n",
    "\n",
    "test_key = 'test.protobuf'\n",
    "test_prefix = '{}/{}'.format(prefix, 'test')\n",
    "\n",
    "\n",
    "def writeDatasetToProtobuf(X, Y, bucket, prefix, key):\n",
    "\n",
    "    buf = io.BytesIO()\n",
    "\n",
    "    # Using SageMaker\n",
    "    smac.write_spmatrix_to_sparse_tensor(buf, X, Y)\n",
    "\n",
    "    buf.seek(0)\n",
    "\n",
    "    bucket_object = '{}/{}'.format(prefix, key)\n",
    "    boto3.resource('s3').Bucket(bucket).Object(bucket_object).upload_fileobj(buf)\n",
    "    return 's3://{}/{}'.format(bucket, bucket_object)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last, write the data by calling the function for the two sets.\n",
    "\n",
    "### 6.1 Serialise the data as ProtoBuf and store in S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data at: s3://pmj-ml-id-lab/sagemaker/recommender-fm/train/train.protobuf\n",
      "Testing data at: s3://pmj-ml-id-lab/sagemaker/recommender-fm/test/test.protobuf\n"
     ]
    }
   ],
   "source": [
    "train_data = writeDatasetToProtobuf(\n",
    "    train_features, train_labels, bucket_name, train_prefix, train_key)\n",
    "print(\"Training data at: %s\" % (train_data))\n",
    "\n",
    "test_data = writeDatasetToProtobuf(\n",
    "    test_features, test_labels, bucket_name, test_prefix, test_key)\n",
    "print(\"Testing data at: %s\" % (test_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Check the Sizes of the Serialised Data\n",
    "You should now see objects at these paths in the S3 console. Note how efficiently the sparse matrix is stored, only 5.8 MB for the training set.\n",
    "\n",
    "You have now finished preparing data and are ready to start training your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.53 Mb\n",
      "0.58 Mb\n"
     ]
    }
   ],
   "source": [
    "def printObjectSize(bucket, prefix, key):\n",
    "    MBFACTOR = float(1<<20)\n",
    "    size = boto3.resource('s3').Bucket(bucket).Object('{}/{}'.format(prefix, key)).content_length\n",
    "    print(round(size/MBFACTOR,2), \"Mb\")\n",
    "\n",
    "printObjectSize(bucket, train_prefix, train_key)\n",
    "printObjectSize(bucket, test_prefix, test_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. Train & Deploy the Model\n",
    "\n",
    "In this part of the lab, you will now invoke Amazon Sagemaker training and testing from the notebook.\n",
    "\n",
    "## 7. Create a factorisation machine and configure its hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a [factorization machine](https://docs.aws.amazon.com/sagemaker/latest/dg/fact-machines.html) Estimator object and set the hyperparameters to be used when training.\n",
    "\n",
    "Wait, what's a factorisation machine?\n",
    "\n",
    "> A factorization machine is a **general-purpose supervised learning algorithm** that you can use for **both classification and regression tasks**. It is an extension of a linear model that is designed to capture interactions between features within high dimensional sparse datasets economically. For example, in a click prediction system, the factorization machine model can capture click rate patterns observed when ads from a certain ad-category are placed on pages from a certain page-category. Factorization machines are a good choice for tasks dealing with high dimensional sparse datasets, such as click prediction and item recommendation.\n",
    "\n",
    "And what are [hyperparameters](https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning))?\n",
    "\n",
    "> In machine learning, a hyperparameter is a parameter whose value is set before the learning process begins. By contrast, the values of other parameters are derived via training.\n",
    "\n",
    "Let's invoke the training process.\n",
    "Note that a warning here is expected... we can ignore it.\n",
    "\n",
    "    WARNING:sagemaker:Couldn't call 'get_role' to get Role ARN from role name pmj-ml-lab1-SagemakerExecutionRole-J02I9C9O0B26 to get Role path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The trained model will be written to: s3://pmj-ml-id-lab/sagemaker/recommender-fm/output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker:Couldn't call 'get_role' to get Role ARN from role name pmj-ml-lab1-SagemakerExecutionRole-J02I9C9O0B26 to get Role path.\n"
     ]
    }
   ],
   "source": [
    "output_prefix  = 's3://{}/{}/output'.format(bucket, prefix)\n",
    "  \n",
    "containers = {'us-west-2': '174872318107.dkr.ecr.us-west-2.amazonaws.com/factorization-machines:latest',\n",
    "             'us-east-1': '382416733822.dkr.ecr.us-east-1.amazonaws.com/factorization-machines:latest',\n",
    "             'us-east-2': '404615174143.dkr.ecr.us-east-2.amazonaws.com/factorization-machines:latest',\n",
    "             'ap-northeast-1': '351501993468.dkr.ecr.ap-northeast-1.amazonaws.com/factorization-machines:latest',\n",
    "             'ap-northeast-2': '835164637446.dkr.ecr.ap-northeast-2.amazonaws.com/factorization-machines:latest',\n",
    "             'ap-southeast-2': '712309505854.dkr.ecr.ap-southeast-2.amazonaws.com/factorization-machines:latest',\n",
    "             'eu-central-1': '664544806723.dkr.ecr.eu-central-1.amazonaws.com/factorization-machines:latest',\n",
    "             'eu-west-1': '438346466558.dkr.ecr.eu-west-1.amazonaws.com/factorization-machines:latest'}\n",
    "  \n",
    "print(\"The trained model will be written to: %s\" % (output_prefix))\n",
    "\n",
    "fm = sagemaker.estimator.Estimator(containers[boto3.Session().region_name],\n",
    "                                  get_execution_role(), \n",
    "                                  train_instance_count=1, \n",
    "                                  train_instance_type='ml.c4.xlarge',\n",
    "                                  output_path=output_prefix,\n",
    "                                  sagemaker_session=sagemaker.Session())\n",
    "  \n",
    "fm.set_hyperparameters(feature_dim=nbFeatures,\n",
    "                     predictor_type='binary_classifier',\n",
    "                     mini_batch_size=1000,\n",
    "                     num_factors=64,\n",
    "                     epochs=100,\n",
    "                     bias_init_sigma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Train the model by calling `fit()`\n",
    "\n",
    "Now, invoke training on Amazon SageMaker.\n",
    "\n",
    "### 8.1 Monitoring the Training Process\n",
    "- While the training is running, Amazon SageMaker will continuously produce output below the cell. \n",
    "- This particular training job should take 4-5 minutes, the training is finished when you see `Billable seconds: ###` at the end of the output.\n",
    "- You can also monitor progress of the training in the Amazon SageMaker console by selecting **Training jobs** in the main menu.\n",
    "\n",
    "### 8.2 Model Output\n",
    "The trained model will be written to the path defined by **output_prefix**, you can verify that there is a **model.tar.gz** object in the S3 console.\n",
    "\n",
    "You have now trained your model and are ready to start using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: factorization-machines-2018-12-20-11-13-07-491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-20 11:13:07 Starting - Starting the training job...\n",
      "2018-12-20 11:13:10 Starting - Launching requested ML instances...\n",
      "2018-12-20 11:14:06 Starting - Preparing the instances for training.........\n",
      "2018-12-20 11:15:15 Downloading - Downloading input data..\n",
      "\u001b[31mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:46 INFO 139924024543040] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-conf.json: {u'factors_lr': u'0.0001', u'linear_init_sigma': u'0.01', u'epochs': 1, u'_wd': u'1.0', u'_num_kv_servers': u'auto', u'use_bias': u'true', u'factors_init_sigma': u'0.001', u'_log_level': u'info', u'bias_init_method': u'normal', u'linear_init_method': u'normal', u'linear_lr': u'0.001', u'factors_init_method': u'normal', u'_tuning_objective_metric': u'', u'bias_wd': u'0.01', u'use_linear': u'true', u'bias_lr': u'0.1', u'mini_batch_size': u'1000', u'_use_full_symbolic': u'true', u'batch_metrics_publish_interval': u'500', u'bias_init_sigma': u'0.01', u'_num_gpus': u'auto', u'_data_format': u'record', u'factors_wd': u'0.00001', u'linear_wd': u'0.001', u'_kvstore': u'auto', u'_learning_rate': u'1.0', u'_optimizer': u'adam'}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:46 INFO 139924024543040] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'predictor_type': u'binary_classifier', u'bias_init_sigma': u'0.1', u'epochs': u'100', u'feature_dim': u'2625', u'num_factors': u'64', u'mini_batch_size': u'1000'}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:46 INFO 139924024543040] Final configuration: {u'factors_lr': u'0.0001', u'linear_init_sigma': u'0.01', u'epochs': u'100', u'feature_dim': u'2625', u'num_factors': u'64', u'_wd': u'1.0', u'_num_kv_servers': u'auto', u'use_bias': u'true', u'factors_init_sigma': u'0.001', u'_log_level': u'info', u'bias_init_method': u'normal', u'linear_init_method': u'normal', u'linear_lr': u'0.001', u'factors_init_method': u'normal', u'_tuning_objective_metric': u'', u'bias_wd': u'0.01', u'use_linear': u'true', u'bias_lr': u'0.1', u'mini_batch_size': u'1000', u'_use_full_symbolic': u'true', u'batch_metrics_publish_interval': u'500', u'predictor_type': u'binary_classifier', u'bias_init_sigma': u'0.1', u'_num_gpus': u'auto', u'_data_format': u'record', u'factors_wd': u'0.00001', u'linear_wd': u'0.001', u'_kvstore': u'auto', u'_learning_rate': u'1.0', u'_optimizer': u'adam'}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:46 WARNING 139924024543040] Loggers have already been setup.\u001b[0m\n",
      "\u001b[31mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:46 INFO 139924024543040] Using default worker.\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:15:46.798] [tensorio] [info] batch={\"data_pipeline\": \"/opt/ml/input/data/train\", \"num_examples\": 1000, \"features\": [{\"name\": \"label_values\", \"shape\": [1], \"storage_type\": \"dense\"}, {\"name\": \"values\", \"shape\": [2625], \"storage_type\": \"CSR\"}]}\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:15:46.801] [tensorio] [warning] TensorIO is already initialized; ignoring the initialization routine.\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:15:46.802] [tensorio] [info] batch={\"data_pipeline\": \"/opt/ml/input/data/test\", \"num_examples\": 1000, \"features\": [{\"name\": \"label_values\", \"shape\": [1], \"storage_type\": \"dense\"}, {\"name\": \"values\", \"shape\": [2625], \"storage_type\": \"CSR\"}]}\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:15:46.806] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 8, \"num_examples\": 1}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:46 INFO 139924024543040] nvidia-smi took: 0.0252001285553 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:46 INFO 139924024543040] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:46 INFO 139924024543040] [Sparse network] Building a sparse network.\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:46 INFO 139924024543040] Create Store: local\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 34.80100631713867, \"sum\": 34.80100631713867, \"min\": 34.80100631713867}}, \"EndTime\": 1545304546.840077, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304546.796745}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Total Records Seen\": {\"count\": 1, \"max\": 1000, \"sum\": 1000.0, \"min\": 1000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1000, \"sum\": 1000.0, \"min\": 1000}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1545304546.840283, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304546.840233}\n",
      "\u001b[0m\n",
      "\u001b[31m[11:15:46] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.201029.0/RHEL5_64/generic-flavor/src/src/kvstore/./kvstore_local.h:280: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use row_sparse_pull with row_ids.\u001b[0m\n",
      "\u001b[31m[11:15:46] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.201029.0/RHEL5_64/generic-flavor/src/src/kvstore/./kvstore_local.h:280: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use row_sparse_pull with row_ids.\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:46 INFO 139924024543040] #quality_metric: host=algo-1, epoch=0, batch=0 train binary_classification_accuracy <score>=0.558\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:46 INFO 139924024543040] #quality_metric: host=algo-1, epoch=0, batch=0 train binary_classification_cross_entropy <loss>=0.686065490723\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:46 INFO 139924024543040] #quality_metric: host=algo-1, epoch=0, batch=0 train binary_f_1.000 <score>=0.716302952503\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:47 INFO 139924024543040] #quality_metric: host=algo-1, epoch=0, train binary_classification_accuracy <score>=0.548417582418\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:47 INFO 139924024543040] #quality_metric: host=algo-1, epoch=0, train binary_classification_cross_entropy <loss>=0.683702715193\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:47 INFO 139924024543040] #quality_metric: host=algo-1, epoch=0, train binary_f_1.000 <score>=0.708358763999\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 100, \"sum\": 100.0, \"min\": 100}, \"update.time\": {\"count\": 1, \"max\": 645.7729339599609, \"sum\": 645.7729339599609, \"min\": 645.7729339599609}}, \"EndTime\": 1545304547.486241, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304546.840175}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:47 INFO 139924024543040] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 92, \"sum\": 92.0, \"min\": 92}, \"Total Records Seen\": {\"count\": 1, \"max\": 91570, \"sum\": 91570.0, \"min\": 91570}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 2, \"sum\": 2.0, \"min\": 2}}, \"EndTime\": 1545304547.486485, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 0}, \"StartTime\": 1545304546.840438}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:47 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=140167.839638 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:15:47.486] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 619, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:47 INFO 139924024543040] #quality_metric: host=algo-1, epoch=1, batch=0 train binary_classification_accuracy <score>=0.642\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:47 INFO 139924024543040] #quality_metric: host=algo-1, epoch=1, batch=0 train binary_classification_cross_entropy <loss>=0.677977539063\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:47 INFO 139924024543040] #quality_metric: host=algo-1, epoch=1, batch=0 train binary_f_1.000 <score>=0.752420470263\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:48 INFO 139924024543040] #quality_metric: host=algo-1, epoch=1, train binary_classification_accuracy <score>=0.564450549451\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:48 INFO 139924024543040] #quality_metric: host=algo-1, epoch=1, train binary_classification_cross_entropy <loss>=0.674212189727\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:48 INFO 139924024543040] #quality_metric: host=algo-1, epoch=1, train binary_f_1.000 <score>=0.706739769003\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 596.2779521942139, \"sum\": 596.2779521942139, \"min\": 596.2779521942139}}, \"EndTime\": 1545304548.083071, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304547.48633}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:48 INFO 139924024543040] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 183, \"sum\": 183.0, \"min\": 183}, \"Total Records Seen\": {\"count\": 1, \"max\": 182140, \"sum\": 182140.0, \"min\": 182140}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 3, \"sum\": 3.0, \"min\": 3}}, \"EndTime\": 1545304548.083289, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 1}, \"StartTime\": 1545304547.486766}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:48 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=151797.01954 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:15:48.083] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 2, \"duration\": 595, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:48 INFO 139924024543040] #quality_metric: host=algo-1, epoch=2, batch=0 train binary_classification_accuracy <score>=0.659\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:48 INFO 139924024543040] #quality_metric: host=algo-1, epoch=2, batch=0 train binary_classification_cross_entropy <loss>=0.66639465332\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:48 INFO 139924024543040] #quality_metric: host=algo-1, epoch=2, batch=0 train binary_f_1.000 <score>=0.759010600707\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:48 INFO 139924024543040] #quality_metric: host=algo-1, epoch=2, train binary_classification_accuracy <score>=0.600736263736\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:48 INFO 139924024543040] #quality_metric: host=algo-1, epoch=2, train binary_classification_cross_entropy <loss>=0.664986809699\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:48 INFO 139924024543040] #quality_metric: host=algo-1, epoch=2, train binary_f_1.000 <score>=0.722451816939\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 583.8849544525146, \"sum\": 583.8849544525146, \"min\": 583.8849544525146}}, \"EndTime\": 1545304548.667475, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304548.083145}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:48 INFO 139924024543040] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 274, \"sum\": 274.0, \"min\": 274}, \"Total Records Seen\": {\"count\": 1, \"max\": 272710, \"sum\": 272710.0, \"min\": 272710}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 4, \"sum\": 4.0, \"min\": 4}}, \"EndTime\": 1545304548.667725, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 2}, \"StartTime\": 1545304548.08356}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:48 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=155009.710916 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:15:48.667] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 3, \"duration\": 582, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:48 INFO 139924024543040] #quality_metric: host=algo-1, epoch=3, batch=0 train binary_classification_accuracy <score>=0.679\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:48 INFO 139924024543040] #quality_metric: host=algo-1, epoch=3, batch=0 train binary_classification_cross_entropy <loss>=0.656495239258\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:48 INFO 139924024543040] #quality_metric: host=algo-1, epoch=3, batch=0 train binary_f_1.000 <score>=0.76688453159\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:49 INFO 139924024543040] #quality_metric: host=algo-1, epoch=3, train binary_classification_accuracy <score>=0.631978021978\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:49 INFO 139924024543040] #quality_metric: host=algo-1, epoch=3, train binary_classification_cross_entropy <loss>=0.656167008285\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:49 INFO 139924024543040] #quality_metric: host=algo-1, epoch=3, train binary_f_1.000 <score>=0.73570402639\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 596.9488620758057, \"sum\": 596.9488620758057, \"min\": 596.9488620758057}}, \"EndTime\": 1545304549.264959, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304548.667556}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:49 INFO 139924024543040] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 365, \"sum\": 365.0, \"min\": 365}, \"Total Records Seen\": {\"count\": 1, \"max\": 363280, \"sum\": 363280.0, \"min\": 363280}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 5, \"sum\": 5.0, \"min\": 5}}, \"EndTime\": 1545304549.265161, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 3}, \"StartTime\": 1545304548.667979}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:49 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=151632.090089 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:15:49.265] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 4, \"duration\": 595, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:49 INFO 139924024543040] #quality_metric: host=algo-1, epoch=4, batch=0 train binary_classification_accuracy <score>=0.695\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:49 INFO 139924024543040] #quality_metric: host=algo-1, epoch=4, batch=0 train binary_classification_cross_entropy <loss>=0.647584350586\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:49 INFO 139924024543040] #quality_metric: host=algo-1, epoch=4, batch=0 train binary_f_1.000 <score>=0.77050413845\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:49 INFO 139924024543040] #quality_metric: host=algo-1, epoch=4, train binary_classification_accuracy <score>=0.654659340659\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:49 INFO 139924024543040] #quality_metric: host=algo-1, epoch=4, train binary_classification_cross_entropy <loss>=0.647875287737\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:49 INFO 139924024543040] #quality_metric: host=algo-1, epoch=4, train binary_f_1.000 <score>=0.744437577256\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 614.6519184112549, \"sum\": 614.6519184112549, \"min\": 614.6519184112549}}, \"EndTime\": 1545304549.880085, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304549.265028}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:49 INFO 139924024543040] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 456, \"sum\": 456.0, \"min\": 456}, \"Total Records Seen\": {\"count\": 1, \"max\": 453850, \"sum\": 453850.0, \"min\": 453850}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}}, \"EndTime\": 1545304549.880345, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 4}, \"StartTime\": 1545304549.265402}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:49 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=147252.021016 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:15:49.880] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 5, \"duration\": 613, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:49 INFO 139924024543040] #quality_metric: host=algo-1, epoch=5, batch=0 train binary_classification_accuracy <score>=0.707\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:49 INFO 139924024543040] #quality_metric: host=algo-1, epoch=5, batch=0 train binary_classification_cross_entropy <loss>=0.639394165039\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:49 INFO 139924024543040] #quality_metric: host=algo-1, epoch=5, batch=0 train binary_f_1.000 <score>=0.774094063223\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:50 INFO 139924024543040] #quality_metric: host=algo-1, epoch=5, train binary_classification_accuracy <score>=0.672406593407\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:50 INFO 139924024543040] #quality_metric: host=algo-1, epoch=5, train binary_classification_cross_entropy <loss>=0.640165837215\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:50 INFO 139924024543040] #quality_metric: host=algo-1, epoch=5, train binary_f_1.000 <score>=0.751369880151\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 597.1698760986328, \"sum\": 597.1698760986328, \"min\": 597.1698760986328}}, \"EndTime\": 1545304550.477848, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304549.88019}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:50 INFO 139924024543040] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 547, \"sum\": 547.0, \"min\": 547}, \"Total Records Seen\": {\"count\": 1, \"max\": 544420, \"sum\": 544420.0, \"min\": 544420}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 7, \"sum\": 7.0, \"min\": 7}}, \"EndTime\": 1545304550.478087, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 5}, \"StartTime\": 1545304549.880621}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:50 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=151555.503581 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:15:50.478] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 6, \"duration\": 595, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:50 INFO 139924024543040] #quality_metric: host=algo-1, epoch=6, batch=0 train binary_classification_accuracy <score>=0.714\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:50 INFO 139924024543040] #quality_metric: host=algo-1, epoch=6, batch=0 train binary_classification_cross_entropy <loss>=0.631862365723\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:50 INFO 139924024543040] #quality_metric: host=algo-1, epoch=6, batch=0 train binary_f_1.000 <score>=0.774447949527\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:51 INFO 139924024543040] #quality_metric: host=algo-1, epoch=6, train binary_classification_accuracy <score>=0.684472527473\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:51 INFO 139924024543040] #quality_metric: host=algo-1, epoch=6, train binary_classification_cross_entropy <loss>=0.633041836581\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:51 INFO 139924024543040] #quality_metric: host=algo-1, epoch=6, train binary_f_1.000 <score>=0.755527931272\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 654.8779010772705, \"sum\": 654.8779010772705, \"min\": 654.8779010772705}}, \"EndTime\": 1545304551.133294, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304550.477923}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:51 INFO 139924024543040] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 638, \"sum\": 638.0, \"min\": 638}, \"Total Records Seen\": {\"count\": 1, \"max\": 634990, \"sum\": 634990.0, \"min\": 634990}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 8, \"sum\": 8.0, \"min\": 8}}, \"EndTime\": 1545304551.133534, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 6}, \"StartTime\": 1545304550.478384}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:51 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=138213.387453 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:15:51.133] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 7, \"duration\": 653, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:51 INFO 139924024543040] #quality_metric: host=algo-1, epoch=7, batch=0 train binary_classification_accuracy <score>=0.716\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:51 INFO 139924024543040] #quality_metric: host=algo-1, epoch=7, batch=0 train binary_classification_cross_entropy <loss>=0.624951293945\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:51 INFO 139924024543040] #quality_metric: host=algo-1, epoch=7, batch=0 train binary_f_1.000 <score>=0.770967741935\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:51 INFO 139924024543040] #quality_metric: host=algo-1, epoch=7, train binary_classification_accuracy <score>=0.693\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:51 INFO 139924024543040] #quality_metric: host=algo-1, epoch=7, train binary_classification_cross_entropy <loss>=0.626480706183\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:51 INFO 139924024543040] #quality_metric: host=algo-1, epoch=7, train binary_f_1.000 <score>=0.758219598951\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 710.360050201416, \"sum\": 710.360050201416, \"min\": 710.360050201416}}, \"EndTime\": 1545304551.844217, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304551.133377}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:51 INFO 139924024543040] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 729, \"sum\": 729.0, \"min\": 729}, \"Total Records Seen\": {\"count\": 1, \"max\": 725560, \"sum\": 725560.0, \"min\": 725560}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 9, \"sum\": 9.0, \"min\": 9}}, \"EndTime\": 1545304551.844424, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 7}, \"StartTime\": 1545304551.133826}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:51 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=127435.037859 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:15:51.844] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 8, \"duration\": 708, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:51 INFO 139924024543040] #quality_metric: host=algo-1, epoch=8, batch=0 train binary_classification_accuracy <score>=0.724\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:51 INFO 139924024543040] #quality_metric: host=algo-1, epoch=8, batch=0 train binary_classification_cross_entropy <loss>=0.618620605469\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:51 INFO 139924024543040] #quality_metric: host=algo-1, epoch=8, batch=0 train binary_f_1.000 <score>=0.774509803922\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:52 INFO 139924024543040] #quality_metric: host=algo-1, epoch=8, train binary_classification_accuracy <score>=0.700428571429\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:52 INFO 139924024543040] #quality_metric: host=algo-1, epoch=8, train binary_classification_cross_entropy <loss>=0.620447774698\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:52 INFO 139924024543040] #quality_metric: host=algo-1, epoch=8, train binary_f_1.000 <score>=0.760828559146\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 774.616003036499, \"sum\": 774.616003036499, \"min\": 774.616003036499}}, \"EndTime\": 1545304552.619312, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304551.844286}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:52 INFO 139924024543040] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 820, \"sum\": 820.0, \"min\": 820}, \"Total Records Seen\": {\"count\": 1, \"max\": 816130, \"sum\": 816130.0, \"min\": 816130}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 10, \"sum\": 10.0, \"min\": 10}}, \"EndTime\": 1545304552.619618, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 8}, \"StartTime\": 1545304551.844663}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:52 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=116851.23703 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:15:52.619] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 9, \"duration\": 773, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:52 INFO 139924024543040] #quality_metric: host=algo-1, epoch=9, batch=0 train binary_classification_accuracy <score>=0.722\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:52 INFO 139924024543040] #quality_metric: host=algo-1, epoch=9, batch=0 train binary_classification_cross_entropy <loss>=0.612827026367\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:52 INFO 139924024543040] #quality_metric: host=algo-1, epoch=9, batch=0 train binary_f_1.000 <score>=0.771381578947\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:53 INFO 139924024543040] #quality_metric: host=algo-1, epoch=9, train binary_classification_accuracy <score>=0.705989010989\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:53 INFO 139924024543040] #quality_metric: host=algo-1, epoch=9, train binary_classification_cross_entropy <loss>=0.614903246534\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:53 INFO 139924024543040] #quality_metric: host=algo-1, epoch=9, train binary_f_1.000 <score>=0.762542933977\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 757.051944732666, \"sum\": 757.051944732666, \"min\": 757.051944732666}}, \"EndTime\": 1545304553.377065, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304552.619399}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:53 INFO 139924024543040] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 911, \"sum\": 911.0, \"min\": 911}, \"Total Records Seen\": {\"count\": 1, \"max\": 906700, \"sum\": 906700.0, \"min\": 906700}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 11, \"sum\": 11.0, \"min\": 11}}, \"EndTime\": 1545304553.377359, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 9}, \"StartTime\": 1545304552.619981}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:53 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=119556.163722 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:15:53.377] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 10, \"duration\": 755, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:53 INFO 139924024543040] #quality_metric: host=algo-1, epoch=10, batch=0 train binary_classification_accuracy <score>=0.724\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:53 INFO 139924024543040] #quality_metric: host=algo-1, epoch=10, batch=0 train binary_classification_cross_entropy <loss>=0.607526062012\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:53 INFO 139924024543040] #quality_metric: host=algo-1, epoch=10, batch=0 train binary_f_1.000 <score>=0.771900826446\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:54 INFO 139924024543040] #quality_metric: host=algo-1, epoch=10, train binary_classification_accuracy <score>=0.710098901099\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:54 INFO 139924024543040] #quality_metric: host=algo-1, epoch=10, train binary_classification_cross_entropy <loss>=0.609806056431\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:54 INFO 139924024543040] #quality_metric: host=algo-1, epoch=10, train binary_f_1.000 <score>=0.763558144746\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 622.8780746459961, \"sum\": 622.8780746459961, \"min\": 622.8780746459961}}, \"EndTime\": 1545304554.000517, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304553.377188}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:54 INFO 139924024543040] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1002, \"sum\": 1002.0, \"min\": 1002}, \"Total Records Seen\": {\"count\": 1, \"max\": 997270, \"sum\": 997270.0, \"min\": 997270}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}}, \"EndTime\": 1545304554.000747, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 10}, \"StartTime\": 1545304553.377608}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:54 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=145315.38901 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:15:54.000] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 11, \"duration\": 621, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:54 INFO 139924024543040] #quality_metric: host=algo-1, epoch=11, batch=0 train binary_classification_accuracy <score>=0.728\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:54 INFO 139924024543040] #quality_metric: host=algo-1, epoch=11, batch=0 train binary_classification_cross_entropy <loss>=0.602673706055\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:54 INFO 139924024543040] #quality_metric: host=algo-1, epoch=11, batch=0 train binary_f_1.000 <score>=0.773710482529\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:54 INFO 139924024543040] #quality_metric: host=algo-1, epoch=11, train binary_classification_accuracy <score>=0.712901098901\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:54 INFO 139924024543040] #quality_metric: host=algo-1, epoch=11, train binary_classification_cross_entropy <loss>=0.605115991613\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:54 INFO 139924024543040] #quality_metric: host=algo-1, epoch=11, train binary_f_1.000 <score>=0.764039666914\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 578.1769752502441, \"sum\": 578.1769752502441, \"min\": 578.1769752502441}}, \"EndTime\": 1545304554.579235, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304554.000594}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:54 INFO 139924024543040] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1093, \"sum\": 1093.0, \"min\": 1093}, \"Total Records Seen\": {\"count\": 1, \"max\": 1087840, \"sum\": 1087840.0, \"min\": 1087840}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 13, \"sum\": 13.0, \"min\": 13}}, \"EndTime\": 1545304554.579451, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 11}, \"StartTime\": 1545304554.001016}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:54 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=156546.253565 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:15:54.579] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 12, \"duration\": 577, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:54 INFO 139924024543040] #quality_metric: host=algo-1, epoch=12, batch=0 train binary_classification_accuracy <score>=0.728\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:54 INFO 139924024543040] #quality_metric: host=algo-1, epoch=12, batch=0 train binary_classification_cross_entropy <loss>=0.598227905273\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:54 INFO 139924024543040] #quality_metric: host=algo-1, epoch=12, batch=0 train binary_f_1.000 <score>=0.772194304858\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:55 INFO 139924024543040] #quality_metric: host=algo-1, epoch=12, train binary_classification_accuracy <score>=0.715725274725\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:55 INFO 139924024543040] #quality_metric: host=algo-1, epoch=12, train binary_classification_cross_entropy <loss>=0.600794841389\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:55 INFO 139924024543040] #quality_metric: host=algo-1, epoch=12, train binary_f_1.000 <score>=0.764808029748\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 575.9057998657227, \"sum\": 575.9057998657227, \"min\": 575.9057998657227}}, \"EndTime\": 1545304555.155646, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304554.579313}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:55 INFO 139924024543040] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1184, \"sum\": 1184.0, \"min\": 1184}, \"Total Records Seen\": {\"count\": 1, \"max\": 1178410, \"sum\": 1178410.0, \"min\": 1178410}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 14, \"sum\": 14.0, \"min\": 14}}, \"EndTime\": 1545304555.155841, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 12}, \"StartTime\": 1545304554.579711}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:55 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=157173.03654 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:15:55.156] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 13, \"duration\": 574, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:55 INFO 139924024543040] #quality_metric: host=algo-1, epoch=13, batch=0 train binary_classification_accuracy <score>=0.731\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:55 INFO 139924024543040] #quality_metric: host=algo-1, epoch=13, batch=0 train binary_classification_cross_entropy <loss>=0.594149169922\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:55 INFO 139924024543040] #quality_metric: host=algo-1, epoch=13, batch=0 train binary_f_1.000 <score>=0.773378264532\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2018-12-20 11:15:44 Training - Training image download completed. Training in progress.\u001b[31m[12/20/2018 11:15:55 INFO 139924024543040] #quality_metric: host=algo-1, epoch=13, train binary_classification_accuracy <score>=0.718208791209\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:55 INFO 139924024543040] #quality_metric: host=algo-1, epoch=13, train binary_classification_cross_entropy <loss>=0.596807039701\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:55 INFO 139924024543040] #quality_metric: host=algo-1, epoch=13, train binary_f_1.000 <score>=0.765511124116\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 594.398021697998, \"sum\": 594.398021697998, \"min\": 594.398021697998}}, \"EndTime\": 1545304555.750512, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304555.155709}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:55 INFO 139924024543040] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1275, \"sum\": 1275.0, \"min\": 1275}, \"Total Records Seen\": {\"count\": 1, \"max\": 1268980, \"sum\": 1268980.0, \"min\": 1268980}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 15, \"sum\": 15.0, \"min\": 15}}, \"EndTime\": 1545304555.75071, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 13}, \"StartTime\": 1545304555.156081}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:55 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=152281.757639 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:15:55.750] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 14, \"duration\": 593, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:55 INFO 139924024543040] #quality_metric: host=algo-1, epoch=14, batch=0 train binary_classification_accuracy <score>=0.732\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:55 INFO 139924024543040] #quality_metric: host=algo-1, epoch=14, batch=0 train binary_classification_cross_entropy <loss>=0.590401000977\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:55 INFO 139924024543040] #quality_metric: host=algo-1, epoch=14, batch=0 train binary_f_1.000 <score>=0.772495755518\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:56 INFO 139924024543040] #quality_metric: host=algo-1, epoch=14, train binary_classification_accuracy <score>=0.720054945055\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:56 INFO 139924024543040] #quality_metric: host=algo-1, epoch=14, train binary_classification_cross_entropy <loss>=0.593119943472\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:56 INFO 139924024543040] #quality_metric: host=algo-1, epoch=14, train binary_f_1.000 <score>=0.765912870887\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 591.0019874572754, \"sum\": 591.0019874572754, \"min\": 591.0019874572754}}, \"EndTime\": 1545304556.342019, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304555.75059}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:56 INFO 139924024543040] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1366, \"sum\": 1366.0, \"min\": 1366}, \"Total Records Seen\": {\"count\": 1, \"max\": 1359550, \"sum\": 1359550.0, \"min\": 1359550}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 16, \"sum\": 16.0, \"min\": 16}}, \"EndTime\": 1545304556.342225, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 14}, \"StartTime\": 1545304555.750989}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:56 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=153150.536533 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:15:56.342] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 15, \"duration\": 589, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:56 INFO 139924024543040] #quality_metric: host=algo-1, epoch=15, batch=0 train binary_classification_accuracy <score>=0.729\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:56 INFO 139924024543040] #quality_metric: host=algo-1, epoch=15, batch=0 train binary_classification_cross_entropy <loss>=0.586949829102\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:56 INFO 139924024543040] #quality_metric: host=algo-1, epoch=15, batch=0 train binary_f_1.000 <score>=0.767780634105\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:56 INFO 139924024543040] #quality_metric: host=algo-1, epoch=15, train binary_classification_accuracy <score>=0.721362637363\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:56 INFO 139924024543040] #quality_metric: host=algo-1, epoch=15, train binary_classification_cross_entropy <loss>=0.589703785655\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:56 INFO 139924024543040] #quality_metric: host=algo-1, epoch=15, train binary_f_1.000 <score>=0.766032443206\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 583.3029747009277, \"sum\": 583.3029747009277, \"min\": 583.3029747009277}}, \"EndTime\": 1545304556.925848, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304556.342076}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:56 INFO 139924024543040] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1457, \"sum\": 1457.0, \"min\": 1457}, \"Total Records Seen\": {\"count\": 1, \"max\": 1450120, \"sum\": 1450120.0, \"min\": 1450120}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 17, \"sum\": 17.0, \"min\": 17}}, \"EndTime\": 1545304556.926124, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 15}, \"StartTime\": 1545304556.342512}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:56 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=155154.186272 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:15:56.926] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 16, \"duration\": 582, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:56 INFO 139924024543040] #quality_metric: host=algo-1, epoch=16, batch=0 train binary_classification_accuracy <score>=0.73\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:56 INFO 139924024543040] #quality_metric: host=algo-1, epoch=16, batch=0 train binary_classification_cross_entropy <loss>=0.583765258789\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:56 INFO 139924024543040] #quality_metric: host=algo-1, epoch=16, batch=0 train binary_f_1.000 <score>=0.768835616438\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:57 INFO 139924024543040] #quality_metric: host=algo-1, epoch=16, train binary_classification_accuracy <score>=0.722824175824\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:57 INFO 139924024543040] #quality_metric: host=algo-1, epoch=16, train binary_classification_cross_entropy <loss>=0.586531694014\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:57 INFO 139924024543040] #quality_metric: host=algo-1, epoch=16, train binary_f_1.000 <score>=0.766438565463\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 606.7099571228027, \"sum\": 606.7099571228027, \"min\": 606.7099571228027}}, \"EndTime\": 1545304557.53314, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304556.925962}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:57 INFO 139924024543040] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1548, \"sum\": 1548.0, \"min\": 1548}, \"Total Records Seen\": {\"count\": 1, \"max\": 1540690, \"sum\": 1540690.0, \"min\": 1540690}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 18, \"sum\": 18.0, \"min\": 18}}, \"EndTime\": 1545304557.533343, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 16}, \"StartTime\": 1545304556.9264}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:57 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=149191.266557 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:15:57.533] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 17, \"duration\": 605, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:57 INFO 139924024543040] #quality_metric: host=algo-1, epoch=17, batch=0 train binary_classification_accuracy <score>=0.724\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:57 INFO 139924024543040] #quality_metric: host=algo-1, epoch=17, batch=0 train binary_classification_cross_entropy <loss>=0.580819885254\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:57 INFO 139924024543040] #quality_metric: host=algo-1, epoch=17, batch=0 train binary_f_1.000 <score>=0.762068965517\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:58 INFO 139924024543040] #quality_metric: host=algo-1, epoch=17, train binary_classification_accuracy <score>=0.723835164835\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:58 INFO 139924024543040] #quality_metric: host=algo-1, epoch=17, train binary_classification_cross_entropy <loss>=0.583579453688\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:58 INFO 139924024543040] #quality_metric: host=algo-1, epoch=17, train binary_f_1.000 <score>=0.766503451672\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 577.1799087524414, \"sum\": 577.1799087524414, \"min\": 577.1799087524414}}, \"EndTime\": 1545304558.110845, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304557.533206}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:58 INFO 139924024543040] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1639, \"sum\": 1639.0, \"min\": 1639}, \"Total Records Seen\": {\"count\": 1, \"max\": 1631260, \"sum\": 1631260.0, \"min\": 1631260}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 19, \"sum\": 19.0, \"min\": 19}}, \"EndTime\": 1545304558.111073, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 17}, \"StartTime\": 1545304557.533633}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:58 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=156813.531108 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:15:58.111] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 18, \"duration\": 575, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:58 INFO 139924024543040] #quality_metric: host=algo-1, epoch=18, batch=0 train binary_classification_accuracy <score>=0.722\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:58 INFO 139924024543040] #quality_metric: host=algo-1, epoch=18, batch=0 train binary_classification_cross_entropy <loss>=0.578088989258\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:58 INFO 139924024543040] #quality_metric: host=algo-1, epoch=18, batch=0 train binary_f_1.000 <score>=0.759098786828\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:58 INFO 139924024543040] #quality_metric: host=algo-1, epoch=18, train binary_classification_accuracy <score>=0.724791208791\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:58 INFO 139924024543040] #quality_metric: host=algo-1, epoch=18, train binary_classification_cross_entropy <loss>=0.580825346224\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:58 INFO 139924024543040] #quality_metric: host=algo-1, epoch=18, train binary_f_1.000 <score>=0.766711379387\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 573.9080905914307, \"sum\": 573.9080905914307, \"min\": 573.9080905914307}}, \"EndTime\": 1545304558.68527, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304558.110896}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:58 INFO 139924024543040] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1730, \"sum\": 1730.0, \"min\": 1730}, \"Total Records Seen\": {\"count\": 1, \"max\": 1721830, \"sum\": 1721830.0, \"min\": 1721830}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 20, \"sum\": 20.0, \"min\": 20}}, \"EndTime\": 1545304558.685477, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 18}, \"StartTime\": 1545304558.111332}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:58 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=157716.803881 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:15:58.685] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 19, \"duration\": 573, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:58 INFO 139924024543040] #quality_metric: host=algo-1, epoch=19, batch=0 train binary_classification_accuracy <score>=0.724\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:58 INFO 139924024543040] #quality_metric: host=algo-1, epoch=19, batch=0 train binary_classification_cross_entropy <loss>=0.575550170898\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:58 INFO 139924024543040] #quality_metric: host=algo-1, epoch=19, batch=0 train binary_f_1.000 <score>=0.759581881533\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:59 INFO 139924024543040] #quality_metric: host=algo-1, epoch=19, train binary_classification_accuracy <score>=0.725681318681\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:59 INFO 139924024543040] #quality_metric: host=algo-1, epoch=19, train binary_classification_cross_entropy <loss>=0.578249902075\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:59 INFO 139924024543040] #quality_metric: host=algo-1, epoch=19, train binary_f_1.000 <score>=0.766807723566\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 586.3428115844727, \"sum\": 586.3428115844727, \"min\": 586.3428115844727}}, \"EndTime\": 1545304559.272085, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304558.685341}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:59 INFO 139924024543040] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1821, \"sum\": 1821.0, \"min\": 1821}, \"Total Records Seen\": {\"count\": 1, \"max\": 1812400, \"sum\": 1812400.0, \"min\": 1812400}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 21, \"sum\": 21.0, \"min\": 21}}, \"EndTime\": 1545304559.272356, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 19}, \"StartTime\": 1545304558.685715}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:59 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=154355.611806 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:15:59.272] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 20, \"duration\": 585, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:59 INFO 139924024543040] #quality_metric: host=algo-1, epoch=20, batch=0 train binary_classification_accuracy <score>=0.722\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:59 INFO 139924024543040] #quality_metric: host=algo-1, epoch=20, batch=0 train binary_classification_cross_entropy <loss>=0.573183959961\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:59 INFO 139924024543040] #quality_metric: host=algo-1, epoch=20, batch=0 train binary_f_1.000 <score>=0.757417102967\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:59 INFO 139924024543040] #quality_metric: host=algo-1, epoch=20, train binary_classification_accuracy <score>=0.726021978022\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:59 INFO 139924024543040] #quality_metric: host=algo-1, epoch=20, train binary_classification_cross_entropy <loss>=0.575835747687\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:59 INFO 139924024543040] #quality_metric: host=algo-1, epoch=20, train binary_f_1.000 <score>=0.766519328738\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 595.3068733215332, \"sum\": 595.3068733215332, \"min\": 595.3068733215332}}, \"EndTime\": 1545304559.867973, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304559.272198}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:59 INFO 139924024543040] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1912, \"sum\": 1912.0, \"min\": 1912}, \"Total Records Seen\": {\"count\": 1, \"max\": 1902970, \"sum\": 1902970.0, \"min\": 1902970}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 22, \"sum\": 22.0, \"min\": 22}}, \"EndTime\": 1545304559.868221, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 20}, \"StartTime\": 1545304559.272635}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:59 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=152036.568234 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:15:59.868] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 21, \"duration\": 594, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:59 INFO 139924024543040] #quality_metric: host=algo-1, epoch=21, batch=0 train binary_classification_accuracy <score>=0.722\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:59 INFO 139924024543040] #quality_metric: host=algo-1, epoch=21, batch=0 train binary_classification_cross_entropy <loss>=0.570972351074\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:15:59 INFO 139924024543040] #quality_metric: host=algo-1, epoch=21, batch=0 train binary_f_1.000 <score>=0.756993006993\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:00 INFO 139924024543040] #quality_metric: host=algo-1, epoch=21, train binary_classification_accuracy <score>=0.727428571429\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:00 INFO 139924024543040] #quality_metric: host=algo-1, epoch=21, train binary_classification_cross_entropy <loss>=0.573567356655\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:00 INFO 139924024543040] #quality_metric: host=algo-1, epoch=21, train binary_f_1.000 <score>=0.76715980775\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 595.7739353179932, \"sum\": 595.7739353179932, \"min\": 595.7739353179932}}, \"EndTime\": 1545304560.464338, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304559.86804}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:00 INFO 139924024543040] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2003, \"sum\": 2003.0, \"min\": 2003}, \"Total Records Seen\": {\"count\": 1, \"max\": 1993540, \"sum\": 1993540.0, \"min\": 1993540}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 23, \"sum\": 23.0, \"min\": 23}}, \"EndTime\": 1545304560.464559, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 21}, \"StartTime\": 1545304559.868532}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:00 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=151913.145495 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:00.464] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 22, \"duration\": 594, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:00 INFO 139924024543040] #quality_metric: host=algo-1, epoch=22, batch=0 train binary_classification_accuracy <score>=0.724\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:00 INFO 139924024543040] #quality_metric: host=algo-1, epoch=22, batch=0 train binary_classification_cross_entropy <loss>=0.568899658203\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:00 INFO 139924024543040] #quality_metric: host=algo-1, epoch=22, batch=0 train binary_f_1.000 <score>=0.758318739054\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:01 INFO 139924024543040] #quality_metric: host=algo-1, epoch=22, train binary_classification_accuracy <score>=0.727879120879\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:01 INFO 139924024543040] #quality_metric: host=algo-1, epoch=22, train binary_classification_cross_entropy <loss>=0.571430869972\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:01 INFO 139924024543040] #quality_metric: host=algo-1, epoch=22, train binary_f_1.000 <score>=0.767083345091\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 634.9530220031738, \"sum\": 634.9530220031738, \"min\": 634.9530220031738}}, \"EndTime\": 1545304561.099834, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304560.464414}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:01 INFO 139924024543040] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2094, \"sum\": 2094.0, \"min\": 2094}, \"Total Records Seen\": {\"count\": 1, \"max\": 2084110, \"sum\": 2084110.0, \"min\": 2084110}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 24, \"sum\": 24.0, \"min\": 24}}, \"EndTime\": 1545304561.100069, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 22}, \"StartTime\": 1545304560.464847}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:01 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=142546.37744 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:01.100] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 23, \"duration\": 633, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:01 INFO 139924024543040] #quality_metric: host=algo-1, epoch=23, batch=0 train binary_classification_accuracy <score>=0.725\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:01 INFO 139924024543040] #quality_metric: host=algo-1, epoch=23, batch=0 train binary_classification_cross_entropy <loss>=0.566951843262\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:01 INFO 139924024543040] #quality_metric: host=algo-1, epoch=23, batch=0 train binary_f_1.000 <score>=0.75898334794\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:01 INFO 139924024543040] #quality_metric: host=algo-1, epoch=23, train binary_classification_accuracy <score>=0.728681318681\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:01 INFO 139924024543040] #quality_metric: host=algo-1, epoch=23, train binary_classification_cross_entropy <loss>=0.569413948478\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:01 INFO 139924024543040] #quality_metric: host=algo-1, epoch=23, train binary_f_1.000 <score>=0.767426525998\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 654.8309326171875, \"sum\": 654.8309326171875, \"min\": 654.8309326171875}}, \"EndTime\": 1545304561.755252, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304561.099912}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:01 INFO 139924024543040] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2185, \"sum\": 2185.0, \"min\": 2185}, \"Total Records Seen\": {\"count\": 1, \"max\": 2174680, \"sum\": 2174680.0, \"min\": 2174680}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 25, \"sum\": 25.0, \"min\": 25}}, \"EndTime\": 1545304561.755466, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 23}, \"StartTime\": 1545304561.100394}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:01 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=138232.599767 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:01.755] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 24, \"duration\": 653, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:01 INFO 139924024543040] #quality_metric: host=algo-1, epoch=24, batch=0 train binary_classification_accuracy <score>=0.727\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:01 INFO 139924024543040] #quality_metric: host=algo-1, epoch=24, batch=0 train binary_classification_cross_entropy <loss>=0.565116516113\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:01 INFO 139924024543040] #quality_metric: host=algo-1, epoch=24, batch=0 train binary_f_1.000 <score>=0.761154855643\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:02 INFO 139924024543040] #quality_metric: host=algo-1, epoch=24, train binary_classification_accuracy <score>=0.729428571429\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:02 INFO 139924024543040] #quality_metric: host=algo-1, epoch=24, train binary_classification_cross_entropy <loss>=0.567505589747\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:02 INFO 139924024543040] #quality_metric: host=algo-1, epoch=24, train binary_f_1.000 <score>=0.767668761441\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 577.0008563995361, \"sum\": 577.0008563995361, \"min\": 577.0008563995361}}, \"EndTime\": 1545304562.332767, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304561.755317}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:02 INFO 139924024543040] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2276, \"sum\": 2276.0, \"min\": 2276}, \"Total Records Seen\": {\"count\": 1, \"max\": 2265250, \"sum\": 2265250.0, \"min\": 2265250}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 26, \"sum\": 26.0, \"min\": 26}}, \"EndTime\": 1545304562.332966, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 24}, \"StartTime\": 1545304561.755736}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:02 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=156871.617725 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:02.333] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 25, \"duration\": 575, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:02 INFO 139924024543040] #quality_metric: host=algo-1, epoch=25, batch=0 train binary_classification_accuracy <score>=0.726\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:02 INFO 139924024543040] #quality_metric: host=algo-1, epoch=25, batch=0 train binary_classification_cross_entropy <loss>=0.563382446289\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:02 INFO 139924024543040] #quality_metric: host=algo-1, epoch=25, batch=0 train binary_f_1.000 <score>=0.760070052539\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:02 INFO 139924024543040] #quality_metric: host=algo-1, epoch=25, train binary_classification_accuracy <score>=0.730296703297\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:02 INFO 139924024543040] #quality_metric: host=algo-1, epoch=25, train binary_classification_cross_entropy <loss>=0.565696006691\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:02 INFO 139924024543040] #quality_metric: host=algo-1, epoch=25, train binary_f_1.000 <score>=0.768083759343\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 576.0970115661621, \"sum\": 576.0970115661621, \"min\": 576.0970115661621}}, \"EndTime\": 1545304562.90933, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304562.332833}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:02 INFO 139924024543040] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2367, \"sum\": 2367.0, \"min\": 2367}, \"Total Records Seen\": {\"count\": 1, \"max\": 2355820, \"sum\": 2355820.0, \"min\": 2355820}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 27, \"sum\": 27.0, \"min\": 27}}, \"EndTime\": 1545304562.909553, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 25}, \"StartTime\": 1545304562.333204}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:02 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=157111.347567 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:02.909] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 26, \"duration\": 574, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:02 INFO 139924024543040] #quality_metric: host=algo-1, epoch=26, batch=0 train binary_classification_accuracy <score>=0.725\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:02 INFO 139924024543040] #quality_metric: host=algo-1, epoch=26, batch=0 train binary_classification_cross_entropy <loss>=0.561739990234\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:02 INFO 139924024543040] #quality_metric: host=algo-1, epoch=26, batch=0 train binary_f_1.000 <score>=0.75898334794\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:03 INFO 139924024543040] #quality_metric: host=algo-1, epoch=26, train binary_classification_accuracy <score>=0.730516483516\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:03 INFO 139924024543040] #quality_metric: host=algo-1, epoch=26, train binary_classification_cross_entropy <loss>=0.563976461893\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:03 INFO 139924024543040] #quality_metric: host=algo-1, epoch=26, train binary_f_1.000 <score>=0.767987738536\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 571.5541839599609, \"sum\": 571.5541839599609, \"min\": 571.5541839599609}}, \"EndTime\": 1545304563.481389, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304562.909404}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:03 INFO 139924024543040] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2458, \"sum\": 2458.0, \"min\": 2458}, \"Total Records Seen\": {\"count\": 1, \"max\": 2446390, \"sum\": 2446390.0, \"min\": 2446390}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 28, \"sum\": 28.0, \"min\": 28}}, \"EndTime\": 1545304563.481613, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 26}, \"StartTime\": 1545304562.909806}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:03 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=158357.437071 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:03.481] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 27, \"duration\": 570, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:03 INFO 139924024543040] #quality_metric: host=algo-1, epoch=27, batch=0 train binary_classification_accuracy <score>=0.727\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:03 INFO 139924024543040] #quality_metric: host=algo-1, epoch=27, batch=0 train binary_classification_cross_entropy <loss>=0.560180297852\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:03 INFO 139924024543040] #quality_metric: host=algo-1, epoch=27, batch=0 train binary_f_1.000 <score>=0.761154855643\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:04 INFO 139924024543040] #quality_metric: host=algo-1, epoch=27, train binary_classification_accuracy <score>=0.731120879121\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:04 INFO 139924024543040] #quality_metric: host=algo-1, epoch=27, train binary_classification_cross_entropy <loss>=0.562339185107\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:04 INFO 139924024543040] #quality_metric: host=algo-1, epoch=27, train binary_f_1.000 <score>=0.768238392028\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 597.8968143463135, \"sum\": 597.8968143463135, \"min\": 597.8968143463135}}, \"EndTime\": 1545304564.079803, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304563.481462}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:04 INFO 139924024543040] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2549, \"sum\": 2549.0, \"min\": 2549}, \"Total Records Seen\": {\"count\": 1, \"max\": 2536960, \"sum\": 2536960.0, \"min\": 2536960}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 29, \"sum\": 29.0, \"min\": 29}}, \"EndTime\": 1545304564.080006, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 27}, \"StartTime\": 1545304563.481874}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:04 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=151391.580916 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:04.080] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 28, \"duration\": 596, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:04 INFO 139924024543040] #quality_metric: host=algo-1, epoch=28, batch=0 train binary_classification_accuracy <score>=0.727\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:04 INFO 139924024543040] #quality_metric: host=algo-1, epoch=28, batch=0 train binary_classification_cross_entropy <loss>=0.558695800781\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:04 INFO 139924024543040] #quality_metric: host=algo-1, epoch=28, batch=0 train binary_f_1.000 <score>=0.760736196319\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:04 INFO 139924024543040] #quality_metric: host=algo-1, epoch=28, train binary_classification_accuracy <score>=0.73143956044\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:04 INFO 139924024543040] #quality_metric: host=algo-1, epoch=28, train binary_classification_cross_entropy <loss>=0.560777269971\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:04 INFO 139924024543040] #quality_metric: host=algo-1, epoch=28, train binary_f_1.000 <score>=0.76828262333\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 595.8869457244873, \"sum\": 595.8869457244873, \"min\": 595.8869457244873}}, \"EndTime\": 1545304564.676208, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304564.079864}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:04 INFO 139924024543040] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2640, \"sum\": 2640.0, \"min\": 2640}, \"Total Records Seen\": {\"count\": 1, \"max\": 2627530, \"sum\": 2627530.0, \"min\": 2627530}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 30, \"sum\": 30.0, \"min\": 30}}, \"EndTime\": 1545304564.676417, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 28}, \"StartTime\": 1545304564.080289}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:04 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=151896.805497 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:04.676] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 29, \"duration\": 594, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:04 INFO 139924024543040] #quality_metric: host=algo-1, epoch=29, batch=0 train binary_classification_accuracy <score>=0.729\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:04 INFO 139924024543040] #quality_metric: host=algo-1, epoch=29, batch=0 train binary_classification_cross_entropy <loss>=0.557279724121\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:04 INFO 139924024543040] #quality_metric: host=algo-1, epoch=29, batch=0 train binary_f_1.000 <score>=0.762071992976\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:05 INFO 139924024543040] #quality_metric: host=algo-1, epoch=29, train binary_classification_accuracy <score>=0.731868131868\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:05 INFO 139924024543040] #quality_metric: host=algo-1, epoch=29, train binary_classification_cross_entropy <loss>=0.559284553276\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:05 INFO 139924024543040] #quality_metric: host=algo-1, epoch=29, train binary_f_1.000 <score>=0.768413059985\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 569.9269771575928, \"sum\": 569.9269771575928, \"min\": 569.9269771575928}}, \"EndTime\": 1545304565.246627, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304564.676279}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:05 INFO 139924024543040] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2731, \"sum\": 2731.0, \"min\": 2731}, \"Total Records Seen\": {\"count\": 1, \"max\": 2718100, \"sum\": 2718100.0, \"min\": 2718100}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 31, \"sum\": 31.0, \"min\": 31}}, \"EndTime\": 1545304565.246828, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 29}, \"StartTime\": 1545304564.676667}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:05 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=158818.626238 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:05.247] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 30, \"duration\": 568, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:05 INFO 139924024543040] #quality_metric: host=algo-1, epoch=30, batch=0 train binary_classification_accuracy <score>=0.729\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:05 INFO 139924024543040] #quality_metric: host=algo-1, epoch=30, batch=0 train binary_classification_cross_entropy <loss>=0.555926025391\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:05 INFO 139924024543040] #quality_metric: host=algo-1, epoch=30, batch=0 train binary_f_1.000 <score>=0.762071992976\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[12/20/2018 11:16:05 INFO 139924024543040] #quality_metric: host=algo-1, epoch=30, train binary_classification_accuracy <score>=0.732142857143\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:05 INFO 139924024543040] #quality_metric: host=algo-1, epoch=30, train binary_classification_cross_entropy <loss>=0.557855535822\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:05 INFO 139924024543040] #quality_metric: host=algo-1, epoch=30, train binary_f_1.000 <score>=0.768410751442\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 599.3161201477051, \"sum\": 599.3161201477051, \"min\": 599.3161201477051}}, \"EndTime\": 1545304565.846439, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304565.246688}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:05 INFO 139924024543040] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2822, \"sum\": 2822.0, \"min\": 2822}, \"Total Records Seen\": {\"count\": 1, \"max\": 2808670, \"sum\": 2808670.0, \"min\": 2808670}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 32, \"sum\": 32.0, \"min\": 32}}, \"EndTime\": 1545304565.84663, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 30}, \"StartTime\": 1545304565.247098}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:05 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=151037.88899 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:05.846] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 31, \"duration\": 597, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:05 INFO 139924024543040] #quality_metric: host=algo-1, epoch=31, batch=0 train binary_classification_accuracy <score>=0.73\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:05 INFO 139924024543040] #quality_metric: host=algo-1, epoch=31, batch=0 train binary_classification_cross_entropy <loss>=0.554629394531\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:05 INFO 139924024543040] #quality_metric: host=algo-1, epoch=31, batch=0 train binary_f_1.000 <score>=0.763157894737\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:06 INFO 139924024543040] #quality_metric: host=algo-1, epoch=31, train binary_classification_accuracy <score>=0.732593406593\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:06 INFO 139924024543040] #quality_metric: host=algo-1, epoch=31, train binary_classification_cross_entropy <loss>=0.556485341502\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:06 INFO 139924024543040] #quality_metric: host=algo-1, epoch=31, train binary_f_1.000 <score>=0.768565015598\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 584.5808982849121, \"sum\": 584.5808982849121, \"min\": 584.5808982849121}}, \"EndTime\": 1545304566.431514, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304565.846491}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:06 INFO 139924024543040] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2913, \"sum\": 2913.0, \"min\": 2913}, \"Total Records Seen\": {\"count\": 1, \"max\": 2899240, \"sum\": 2899240.0, \"min\": 2899240}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 33, \"sum\": 33.0, \"min\": 33}}, \"EndTime\": 1545304566.431747, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 31}, \"StartTime\": 1545304565.846901}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:06 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=154827.948597 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:06.431] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 32, \"duration\": 583, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:06 INFO 139924024543040] #quality_metric: host=algo-1, epoch=32, batch=0 train binary_classification_accuracy <score>=0.73\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:06 INFO 139924024543040] #quality_metric: host=algo-1, epoch=32, batch=0 train binary_classification_cross_entropy <loss>=0.553385131836\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:06 INFO 139924024543040] #quality_metric: host=algo-1, epoch=32, batch=0 train binary_f_1.000 <score>=0.762323943662\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:07 INFO 139924024543040] #quality_metric: host=algo-1, epoch=32, train binary_classification_accuracy <score>=0.732791208791\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:07 INFO 139924024543040] #quality_metric: host=algo-1, epoch=32, train binary_classification_cross_entropy <loss>=0.555169580481\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:07 INFO 139924024543040] #quality_metric: host=algo-1, epoch=32, train binary_f_1.000 <score>=0.768551304017\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 598.9358425140381, \"sum\": 598.9358425140381, \"min\": 598.9358425140381}}, \"EndTime\": 1545304567.030986, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304566.431583}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:07 INFO 139924024543040] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3004, \"sum\": 3004.0, \"min\": 3004}, \"Total Records Seen\": {\"count\": 1, \"max\": 2989810, \"sum\": 2989810.0, \"min\": 2989810}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 34, \"sum\": 34.0, \"min\": 34}}, \"EndTime\": 1545304567.031195, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 32}, \"StartTime\": 1545304566.432019}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:07 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=151128.561873 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:07.031] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 33, \"duration\": 598, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:07 INFO 139924024543040] #quality_metric: host=algo-1, epoch=33, batch=0 train binary_classification_accuracy <score>=0.731\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:07 INFO 139924024543040] #quality_metric: host=algo-1, epoch=33, batch=0 train binary_classification_cross_entropy <loss>=0.552189208984\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:07 INFO 139924024543040] #quality_metric: host=algo-1, epoch=33, batch=0 train binary_f_1.000 <score>=0.763412489006\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:07 INFO 139924024543040] #quality_metric: host=algo-1, epoch=33, train binary_classification_accuracy <score>=0.733197802198\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:07 INFO 139924024543040] #quality_metric: host=algo-1, epoch=33, train binary_classification_cross_entropy <loss>=0.553904361264\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:07 INFO 139924024543040] #quality_metric: host=algo-1, epoch=33, train binary_f_1.000 <score>=0.768711954503\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 595.4239368438721, \"sum\": 595.4239368438721, \"min\": 595.4239368438721}}, \"EndTime\": 1545304567.626882, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304567.031058}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:07 INFO 139924024543040] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3095, \"sum\": 3095.0, \"min\": 3095}, \"Total Records Seen\": {\"count\": 1, \"max\": 3080380, \"sum\": 3080380.0, \"min\": 3080380}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 35, \"sum\": 35.0, \"min\": 35}}, \"EndTime\": 1545304567.627106, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 33}, \"StartTime\": 1545304567.031428}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:07 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=152014.604999 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:07.627] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 34, \"duration\": 594, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:07 INFO 139924024543040] #quality_metric: host=algo-1, epoch=34, batch=0 train binary_classification_accuracy <score>=0.73\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:07 INFO 139924024543040] #quality_metric: host=algo-1, epoch=34, batch=0 train binary_classification_cross_entropy <loss>=0.551037780762\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:07 INFO 139924024543040] #quality_metric: host=algo-1, epoch=34, batch=0 train binary_f_1.000 <score>=0.762323943662\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:08 INFO 139924024543040] #quality_metric: host=algo-1, epoch=34, train binary_classification_accuracy <score>=0.733406593407\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:08 INFO 139924024543040] #quality_metric: host=algo-1, epoch=34, train binary_classification_cross_entropy <loss>=0.552686186738\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:08 INFO 139924024543040] #quality_metric: host=algo-1, epoch=34, train binary_f_1.000 <score>=0.768705666997\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 594.0580368041992, \"sum\": 594.0580368041992, \"min\": 594.0580368041992}}, \"EndTime\": 1545304568.221463, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304567.626951}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:08 INFO 139924024543040] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3186, \"sum\": 3186.0, \"min\": 3186}, \"Total Records Seen\": {\"count\": 1, \"max\": 3170950, \"sum\": 3170950.0, \"min\": 3170950}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 36, \"sum\": 36.0, \"min\": 36}}, \"EndTime\": 1545304568.221668, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 34}, \"StartTime\": 1545304567.627375}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:08 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=152368.796763 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:08.221] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 35, \"duration\": 593, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:08 INFO 139924024543040] #quality_metric: host=algo-1, epoch=35, batch=0 train binary_classification_accuracy <score>=0.73\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:08 INFO 139924024543040] #quality_metric: host=algo-1, epoch=35, batch=0 train binary_classification_cross_entropy <loss>=0.549927734375\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:08 INFO 139924024543040] #quality_metric: host=algo-1, epoch=35, batch=0 train binary_f_1.000 <score>=0.762323943662\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:08 INFO 139924024543040] #quality_metric: host=algo-1, epoch=35, train binary_classification_accuracy <score>=0.733681318681\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:08 INFO 139924024543040] #quality_metric: host=algo-1, epoch=35, train binary_classification_cross_entropy <loss>=0.551511928013\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:08 INFO 139924024543040] #quality_metric: host=algo-1, epoch=35, train binary_f_1.000 <score>=0.768813973233\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 592.4999713897705, \"sum\": 592.4999713897705, \"min\": 592.4999713897705}}, \"EndTime\": 1545304568.814434, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304568.221533}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:08 INFO 139924024543040] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3277, \"sum\": 3277.0, \"min\": 3277}, \"Total Records Seen\": {\"count\": 1, \"max\": 3261520, \"sum\": 3261520.0, \"min\": 3261520}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 37, \"sum\": 37.0, \"min\": 37}}, \"EndTime\": 1545304568.814641, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 35}, \"StartTime\": 1545304568.221906}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:08 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=152771.813275 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:08.814] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 36, \"duration\": 591, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:08 INFO 139924024543040] #quality_metric: host=algo-1, epoch=36, batch=0 train binary_classification_accuracy <score>=0.731\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:08 INFO 139924024543040] #quality_metric: host=algo-1, epoch=36, batch=0 train binary_classification_cross_entropy <loss>=0.548856201172\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:08 INFO 139924024543040] #quality_metric: host=algo-1, epoch=36, batch=0 train binary_f_1.000 <score>=0.763412489006\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:09 INFO 139924024543040] #quality_metric: host=algo-1, epoch=36, train binary_classification_accuracy <score>=0.73389010989\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:09 INFO 139924024543040] #quality_metric: host=algo-1, epoch=36, train binary_classification_cross_entropy <loss>=0.550378781497\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:09 INFO 139924024543040] #quality_metric: host=algo-1, epoch=36, train binary_f_1.000 <score>=0.768838656714\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 568.1171417236328, \"sum\": 568.1171417236328, \"min\": 568.1171417236328}}, \"EndTime\": 1545304569.383016, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304568.814506}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:09 INFO 139924024543040] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3368, \"sum\": 3368.0, \"min\": 3368}, \"Total Records Seen\": {\"count\": 1, \"max\": 3352090, \"sum\": 3352090.0, \"min\": 3352090}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 38, \"sum\": 38.0, \"min\": 38}}, \"EndTime\": 1545304569.383275, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 36}, \"StartTime\": 1545304568.814868}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:09 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=159305.621175 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:09.383] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 37, \"duration\": 566, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:09 INFO 139924024543040] #quality_metric: host=algo-1, epoch=37, batch=0 train binary_classification_accuracy <score>=0.732\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:09 INFO 139924024543040] #quality_metric: host=algo-1, epoch=37, batch=0 train binary_classification_cross_entropy <loss>=0.547820617676\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:09 INFO 139924024543040] #quality_metric: host=algo-1, epoch=37, batch=0 train binary_f_1.000 <score>=0.764499121265\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:09 INFO 139924024543040] #quality_metric: host=algo-1, epoch=37, train binary_classification_accuracy <score>=0.73432967033\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:09 INFO 139924024543040] #quality_metric: host=algo-1, epoch=37, train binary_classification_cross_entropy <loss>=0.549284197797\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:09 INFO 139924024543040] #quality_metric: host=algo-1, epoch=37, train binary_f_1.000 <score>=0.76904852885\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 571.0811614990234, \"sum\": 571.0811614990234, \"min\": 571.0811614990234}}, \"EndTime\": 1545304569.954696, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304569.383119}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:09 INFO 139924024543040] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3459, \"sum\": 3459.0, \"min\": 3459}, \"Total Records Seen\": {\"count\": 1, \"max\": 3442660, \"sum\": 3442660.0, \"min\": 3442660}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 39, \"sum\": 39.0, \"min\": 39}}, \"EndTime\": 1545304569.954942, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 37}, \"StartTime\": 1545304569.383537}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:09 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=158470.202331 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:09.955] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 38, \"duration\": 569, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:09 INFO 139924024543040] #quality_metric: host=algo-1, epoch=38, batch=0 train binary_classification_accuracy <score>=0.734\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:09 INFO 139924024543040] #quality_metric: host=algo-1, epoch=38, batch=0 train binary_classification_cross_entropy <loss>=0.546818603516\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:09 INFO 139924024543040] #quality_metric: host=algo-1, epoch=38, batch=0 train binary_f_1.000 <score>=0.765845070423\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:10 INFO 139924024543040] #quality_metric: host=algo-1, epoch=38, train binary_classification_accuracy <score>=0.734747252747\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:10 INFO 139924024543040] #quality_metric: host=algo-1, epoch=38, train binary_classification_cross_entropy <loss>=0.54822590654\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:10 INFO 139924024543040] #quality_metric: host=algo-1, epoch=38, train binary_f_1.000 <score>=0.769301347606\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 580.0549983978271, \"sum\": 580.0549983978271, \"min\": 580.0549983978271}}, \"EndTime\": 1545304570.535263, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304569.954774}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:10 INFO 139924024543040] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3550, \"sum\": 3550.0, \"min\": 3550}, \"Total Records Seen\": {\"count\": 1, \"max\": 3533230, \"sum\": 3533230.0, \"min\": 3533230}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 40, \"sum\": 40.0, \"min\": 40}}, \"EndTime\": 1545304570.535496, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 38}, \"StartTime\": 1545304569.955177}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:10 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=156034.672696 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:10.535] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 39, \"duration\": 578, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:10 INFO 139924024543040] #quality_metric: host=algo-1, epoch=39, batch=0 train binary_classification_accuracy <score>=0.731\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:10 INFO 139924024543040] #quality_metric: host=algo-1, epoch=39, batch=0 train binary_classification_cross_entropy <loss>=0.545848266602\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:10 INFO 139924024543040] #quality_metric: host=algo-1, epoch=39, batch=0 train binary_f_1.000 <score>=0.762995594714\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:11 INFO 139924024543040] #quality_metric: host=algo-1, epoch=39, train binary_classification_accuracy <score>=0.734989010989\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:11 INFO 139924024543040] #quality_metric: host=algo-1, epoch=39, train binary_classification_cross_entropy <loss>=0.547201838567\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:11 INFO 139924024543040] #quality_metric: host=algo-1, epoch=39, train binary_f_1.000 <score>=0.769405825094\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 559.196949005127, \"sum\": 559.196949005127, \"min\": 559.196949005127}}, \"EndTime\": 1545304571.094977, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304570.535337}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:11 INFO 139924024543040] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3641, \"sum\": 3641.0, \"min\": 3641}, \"Total Records Seen\": {\"count\": 1, \"max\": 3623800, \"sum\": 3623800.0, \"min\": 3623800}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 41, \"sum\": 41.0, \"min\": 41}}, \"EndTime\": 1545304571.095184, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 39}, \"StartTime\": 1545304570.535751}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:11 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=161863.990316 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:11.095] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 40, \"duration\": 558, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:11 INFO 139924024543040] #quality_metric: host=algo-1, epoch=40, batch=0 train binary_classification_accuracy <score>=0.729\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:11 INFO 139924024543040] #quality_metric: host=algo-1, epoch=40, batch=0 train binary_classification_cross_entropy <loss>=0.544907714844\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:11 INFO 139924024543040] #quality_metric: host=algo-1, epoch=40, batch=0 train binary_f_1.000 <score>=0.76081200353\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:11 INFO 139924024543040] #quality_metric: host=algo-1, epoch=40, train binary_classification_accuracy <score>=0.735340659341\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:11 INFO 139924024543040] #quality_metric: host=algo-1, epoch=40, train binary_classification_cross_entropy <loss>=0.546210125263\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:11 INFO 139924024543040] #quality_metric: host=algo-1, epoch=40, train binary_f_1.000 <score>=0.769614876887\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 594.6700572967529, \"sum\": 594.6700572967529, \"min\": 594.6700572967529}}, \"EndTime\": 1545304571.690114, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304571.095048}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:11 INFO 139924024543040] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3732, \"sum\": 3732.0, \"min\": 3732}, \"Total Records Seen\": {\"count\": 1, \"max\": 3714370, \"sum\": 3714370.0, \"min\": 3714370}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 42, \"sum\": 42.0, \"min\": 42}}, \"EndTime\": 1545304571.69032, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 40}, \"StartTime\": 1545304571.095415}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:11 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=152213.112751 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:11.690] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 41, \"duration\": 593, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:11 INFO 139924024543040] #quality_metric: host=algo-1, epoch=41, batch=0 train binary_classification_accuracy <score>=0.728\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:11 INFO 139924024543040] #quality_metric: host=algo-1, epoch=41, batch=0 train binary_classification_cross_entropy <loss>=0.543995239258\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:11 INFO 139924024543040] #quality_metric: host=algo-1, epoch=41, batch=0 train binary_f_1.000 <score>=0.759717314488\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:12 INFO 139924024543040] #quality_metric: host=algo-1, epoch=41, train binary_classification_accuracy <score>=0.735461538462\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:12 INFO 139924024543040] #quality_metric: host=algo-1, epoch=41, train binary_classification_cross_entropy <loss>=0.545249050266\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:12 INFO 139924024543040] #quality_metric: host=algo-1, epoch=41, train binary_f_1.000 <score>=0.769603292339\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 625.5409717559814, \"sum\": 625.5409717559814, \"min\": 625.5409717559814}}, \"EndTime\": 1545304572.316155, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304571.690186}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:12 INFO 139924024543040] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3823, \"sum\": 3823.0, \"min\": 3823}, \"Total Records Seen\": {\"count\": 1, \"max\": 3804940, \"sum\": 3804940.0, \"min\": 3804940}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 43, \"sum\": 43.0, \"min\": 43}}, \"EndTime\": 1545304572.316386, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 41}, \"StartTime\": 1545304571.690558}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:12 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=144691.604501 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:12.316] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 42, \"duration\": 624, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:12 INFO 139924024543040] #quality_metric: host=algo-1, epoch=42, batch=0 train binary_classification_accuracy <score>=0.728\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:12 INFO 139924024543040] #quality_metric: host=algo-1, epoch=42, batch=0 train binary_classification_cross_entropy <loss>=0.54310949707\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:12 INFO 139924024543040] #quality_metric: host=algo-1, epoch=42, batch=0 train binary_f_1.000 <score>=0.759717314488\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:12 INFO 139924024543040] #quality_metric: host=algo-1, epoch=42, train binary_classification_accuracy <score>=0.735549450549\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:12 INFO 139924024543040] #quality_metric: host=algo-1, epoch=42, train binary_classification_cross_entropy <loss>=0.544317057515\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:12 INFO 139924024543040] #quality_metric: host=algo-1, epoch=42, train binary_f_1.000 <score>=0.769551935802\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 580.9662342071533, \"sum\": 580.9662342071533, \"min\": 580.9662342071533}}, \"EndTime\": 1545304572.897649, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304572.316233}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:12 INFO 139924024543040] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3914, \"sum\": 3914.0, \"min\": 3914}, \"Total Records Seen\": {\"count\": 1, \"max\": 3895510, \"sum\": 3895510.0, \"min\": 3895510}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 44, \"sum\": 44.0, \"min\": 44}}, \"EndTime\": 1545304572.897857, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 42}, \"StartTime\": 1545304572.316654}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:12 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=155799.30109 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:12.898] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 43, \"duration\": 579, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:12 INFO 139924024543040] #quality_metric: host=algo-1, epoch=43, batch=0 train binary_classification_accuracy <score>=0.727\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:12 INFO 139924024543040] #quality_metric: host=algo-1, epoch=43, batch=0 train binary_classification_cross_entropy <loss>=0.542249084473\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:12 INFO 139924024543040] #quality_metric: host=algo-1, epoch=43, batch=0 train binary_f_1.000 <score>=0.759046778464\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:13 INFO 139924024543040] #quality_metric: host=algo-1, epoch=43, train binary_classification_accuracy <score>=0.736065934066\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:13 INFO 139924024543040] #quality_metric: host=algo-1, epoch=43, train binary_classification_cross_entropy <loss>=0.543412727104\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:13 INFO 139924024543040] #quality_metric: host=algo-1, epoch=43, train binary_f_1.000 <score>=0.7698896298\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 591.2530422210693, \"sum\": 591.2530422210693, \"min\": 591.2530422210693}}, \"EndTime\": 1545304573.489384, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304572.897723}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:13 INFO 139924024543040] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 4005, \"sum\": 4005.0, \"min\": 4005}, \"Total Records Seen\": {\"count\": 1, \"max\": 3986080, \"sum\": 3986080.0, \"min\": 3986080}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}}, \"EndTime\": 1545304573.489649, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 43}, \"StartTime\": 1545304572.898102}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:13 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=153078.022016 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:13.489] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 44, \"duration\": 590, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:13 INFO 139924024543040] #quality_metric: host=algo-1, epoch=44, batch=0 train binary_classification_accuracy <score>=0.727\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:13 INFO 139924024543040] #quality_metric: host=algo-1, epoch=44, batch=0 train binary_classification_cross_entropy <loss>=0.541412719727\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:13 INFO 139924024543040] #quality_metric: host=algo-1, epoch=44, batch=0 train binary_f_1.000 <score>=0.759046778464\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:14 INFO 139924024543040] #quality_metric: host=algo-1, epoch=44, train binary_classification_accuracy <score>=0.736384615385\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:14 INFO 139924024543040] #quality_metric: host=algo-1, epoch=44, train binary_classification_cross_entropy <loss>=0.542534733699\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:14 INFO 139924024543040] #quality_metric: host=algo-1, epoch=44, train binary_f_1.000 <score>=0.770103596653\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 572.6840496063232, \"sum\": 572.6840496063232, \"min\": 572.6840496063232}}, \"EndTime\": 1545304574.062598, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304573.489506}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:14 INFO 139924024543040] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 4096, \"sum\": 4096.0, \"min\": 4096}, \"Total Records Seen\": {\"count\": 1, \"max\": 4076650, \"sum\": 4076650.0, \"min\": 4076650}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 46, \"sum\": 46.0, \"min\": 46}}, \"EndTime\": 1545304574.062837, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 44}, \"StartTime\": 1545304573.489884}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:14 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=158039.955868 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:14.063] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 45, \"duration\": 571, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:14 INFO 139924024543040] #quality_metric: host=algo-1, epoch=45, batch=0 train binary_classification_accuracy <score>=0.729\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:14 INFO 139924024543040] #quality_metric: host=algo-1, epoch=45, batch=0 train binary_classification_cross_entropy <loss>=0.54059942627\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:14 INFO 139924024543040] #quality_metric: host=algo-1, epoch=45, batch=0 train binary_f_1.000 <score>=0.761233480176\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:14 INFO 139924024543040] #quality_metric: host=algo-1, epoch=45, train binary_classification_accuracy <score>=0.736692307692\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:14 INFO 139924024543040] #quality_metric: host=algo-1, epoch=45, train binary_classification_cross_entropy <loss>=0.541681872693\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:14 INFO 139924024543040] #quality_metric: host=algo-1, epoch=45, train binary_f_1.000 <score>=0.770301490677\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 622.8129863739014, \"sum\": 622.8129863739014, \"min\": 622.8129863739014}}, \"EndTime\": 1545304574.685976, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304574.062678}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:14 INFO 139924024543040] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 4187, \"sum\": 4187.0, \"min\": 4187}, \"Total Records Seen\": {\"count\": 1, \"max\": 4167220, \"sum\": 4167220.0, \"min\": 4167220}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 47, \"sum\": 47.0, \"min\": 47}}, \"EndTime\": 1545304574.686199, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 45}, \"StartTime\": 1545304574.063133}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:14 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=145331.678041 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:14.686] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 46, \"duration\": 621, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:14 INFO 139924024543040] #quality_metric: host=algo-1, epoch=46, batch=0 train binary_classification_accuracy <score>=0.73\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:14 INFO 139924024543040] #quality_metric: host=algo-1, epoch=46, batch=0 train binary_classification_cross_entropy <loss>=0.539808105469\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:14 INFO 139924024543040] #quality_metric: host=algo-1, epoch=46, batch=0 train binary_f_1.000 <score>=0.761904761905\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:15 INFO 139924024543040] #quality_metric: host=algo-1, epoch=46, train binary_classification_accuracy <score>=0.736802197802\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:15 INFO 139924024543040] #quality_metric: host=algo-1, epoch=46, train binary_classification_cross_entropy <loss>=0.540853019966\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:15 INFO 139924024543040] #quality_metric: host=algo-1, epoch=46, train binary_f_1.000 <score>=0.770326898919\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 564.5320415496826, \"sum\": 564.5320415496826, \"min\": 564.5320415496826}}, \"EndTime\": 1545304575.251053, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304574.686051}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:15 INFO 139924024543040] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 4278, \"sum\": 4278.0, \"min\": 4278}, \"Total Records Seen\": {\"count\": 1, \"max\": 4257790, \"sum\": 4257790.0, \"min\": 4257790}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 48, \"sum\": 48.0, \"min\": 48}}, \"EndTime\": 1545304575.251258, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 46}, \"StartTime\": 1545304574.68649}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:15 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=160325.291824 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:15.251] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 47, \"duration\": 563, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:15 INFO 139924024543040] #quality_metric: host=algo-1, epoch=47, batch=0 train binary_classification_accuracy <score>=0.731\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:15 INFO 139924024543040] #quality_metric: host=algo-1, epoch=47, batch=0 train binary_classification_cross_entropy <loss>=0.539037841797\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:15 INFO 139924024543040] #quality_metric: host=algo-1, epoch=47, batch=0 train binary_f_1.000 <score>=0.762577228597\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[12/20/2018 11:16:15 INFO 139924024543040] #quality_metric: host=algo-1, epoch=47, train binary_classification_accuracy <score>=0.736824175824\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:15 INFO 139924024543040] #quality_metric: host=algo-1, epoch=47, train binary_classification_cross_entropy <loss>=0.540047135909\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:15 INFO 139924024543040] #quality_metric: host=algo-1, epoch=47, train binary_f_1.000 <score>=0.770257954971\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 584.3830108642578, \"sum\": 584.3830108642578, \"min\": 584.3830108642578}}, \"EndTime\": 1545304575.83591, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304575.251122}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:15 INFO 139924024543040] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 4369, \"sum\": 4369.0, \"min\": 4369}, \"Total Records Seen\": {\"count\": 1, \"max\": 4348360, \"sum\": 4348360.0, \"min\": 4348360}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 49, \"sum\": 49.0, \"min\": 49}}, \"EndTime\": 1545304575.836152, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 47}, \"StartTime\": 1545304575.251498}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:15 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=154878.763704 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:15.836] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 48, \"duration\": 583, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:15 INFO 139924024543040] #quality_metric: host=algo-1, epoch=48, batch=0 train binary_classification_accuracy <score>=0.731\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:15 INFO 139924024543040] #quality_metric: host=algo-1, epoch=48, batch=0 train binary_classification_cross_entropy <loss>=0.538287780762\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:15 INFO 139924024543040] #quality_metric: host=algo-1, epoch=48, batch=0 train binary_f_1.000 <score>=0.762577228597\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:16 INFO 139924024543040] #quality_metric: host=algo-1, epoch=48, train binary_classification_accuracy <score>=0.737186813187\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:16 INFO 139924024543040] #quality_metric: host=algo-1, epoch=48, train binary_classification_cross_entropy <loss>=0.539263242617\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:16 INFO 139924024543040] #quality_metric: host=algo-1, epoch=48, train binary_f_1.000 <score>=0.770506275669\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 608.7019443511963, \"sum\": 608.7019443511963, \"min\": 608.7019443511963}}, \"EndTime\": 1545304576.445152, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304575.835985}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:16 INFO 139924024543040] #progress_metric: host=algo-1, completed 49 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 4460, \"sum\": 4460.0, \"min\": 4460}, \"Total Records Seen\": {\"count\": 1, \"max\": 4438930, \"sum\": 4438930.0, \"min\": 4438930}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 50, \"sum\": 50.0, \"min\": 50}}, \"EndTime\": 1545304576.445357, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 48}, \"StartTime\": 1545304575.836422}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:16 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=148704.316306 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:16.445] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 49, \"duration\": 607, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:16 INFO 139924024543040] #quality_metric: host=algo-1, epoch=49, batch=0 train binary_classification_accuracy <score>=0.732\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:16 INFO 139924024543040] #quality_metric: host=algo-1, epoch=49, batch=0 train binary_classification_cross_entropy <loss>=0.537557006836\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:16 INFO 139924024543040] #quality_metric: host=algo-1, epoch=49, batch=0 train binary_f_1.000 <score>=0.763250883392\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:17 INFO 139924024543040] #quality_metric: host=algo-1, epoch=49, train binary_classification_accuracy <score>=0.737516483516\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:17 INFO 139924024543040] #quality_metric: host=algo-1, epoch=49, train binary_classification_cross_entropy <loss>=0.538500437978\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:17 INFO 139924024543040] #quality_metric: host=algo-1, epoch=49, train binary_f_1.000 <score>=0.770736951222\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 582.5979709625244, \"sum\": 582.5979709625244, \"min\": 582.5979709625244}}, \"EndTime\": 1545304577.028304, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304576.445209}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:17 INFO 139924024543040] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 4551, \"sum\": 4551.0, \"min\": 4551}, \"Total Records Seen\": {\"count\": 1, \"max\": 4529500, \"sum\": 4529500.0, \"min\": 4529500}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 51, \"sum\": 51.0, \"min\": 51}}, \"EndTime\": 1545304577.028576, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 49}, \"StartTime\": 1545304576.445674}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:17 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=155338.303824 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:17.028] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 50, \"duration\": 581, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:17 INFO 139924024543040] #quality_metric: host=algo-1, epoch=50, batch=0 train binary_classification_accuracy <score>=0.733\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:17 INFO 139924024543040] #quality_metric: host=algo-1, epoch=50, batch=0 train binary_classification_cross_entropy <loss>=0.536844909668\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:17 INFO 139924024543040] #quality_metric: host=algo-1, epoch=50, batch=0 train binary_f_1.000 <score>=0.764342453663\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:17 INFO 139924024543040] #quality_metric: host=algo-1, epoch=50, train binary_classification_accuracy <score>=0.737692307692\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:17 INFO 139924024543040] #quality_metric: host=algo-1, epoch=50, train binary_classification_cross_entropy <loss>=0.537757858109\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:17 INFO 139924024543040] #quality_metric: host=algo-1, epoch=50, train binary_f_1.000 <score>=0.770828932967\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 590.6491279602051, \"sum\": 590.6491279602051, \"min\": 590.6491279602051}}, \"EndTime\": 1545304577.619623, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304577.028396}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:17 INFO 139924024543040] #progress_metric: host=algo-1, completed 51 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 4642, \"sum\": 4642.0, \"min\": 4642}, \"Total Records Seen\": {\"count\": 1, \"max\": 4620070, \"sum\": 4620070.0, \"min\": 4620070}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 52, \"sum\": 52.0, \"min\": 52}}, \"EndTime\": 1545304577.619822, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 50}, \"StartTime\": 1545304577.028942}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:17 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=153244.629989 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:17.619] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 51, \"duration\": 589, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:17 INFO 139924024543040] #quality_metric: host=algo-1, epoch=51, batch=0 train binary_classification_accuracy <score>=0.732\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:17 INFO 139924024543040] #quality_metric: host=algo-1, epoch=51, batch=0 train binary_classification_cross_entropy <loss>=0.536150695801\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:17 INFO 139924024543040] #quality_metric: host=algo-1, epoch=51, batch=0 train binary_f_1.000 <score>=0.762831858407\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:18 INFO 139924024543040] #quality_metric: host=algo-1, epoch=51, train binary_classification_accuracy <score>=0.742659340659\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:18 INFO 139924024543040] #quality_metric: host=algo-1, epoch=51, train binary_classification_cross_entropy <loss>=0.537034713577\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:18 INFO 139924024543040] #quality_metric: host=algo-1, epoch=51, train binary_f_1.000 <score>=0.774197280879\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 567.9287910461426, \"sum\": 567.9287910461426, \"min\": 567.9287910461426}}, \"EndTime\": 1545304578.188008, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304577.619688}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:18 INFO 139924024543040] #progress_metric: host=algo-1, completed 52 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 4733, \"sum\": 4733.0, \"min\": 4733}, \"Total Records Seen\": {\"count\": 1, \"max\": 4710640, \"sum\": 4710640.0, \"min\": 4710640}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 53, \"sum\": 53.0, \"min\": 53}}, \"EndTime\": 1545304578.188241, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 51}, \"StartTime\": 1545304577.62005}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:18 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=159368.978809 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:18.188] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 52, \"duration\": 566, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:18 INFO 139924024543040] #quality_metric: host=algo-1, epoch=52, batch=0 train binary_classification_accuracy <score>=0.731\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:18 INFO 139924024543040] #quality_metric: host=algo-1, epoch=52, batch=0 train binary_classification_cross_entropy <loss>=0.535473754883\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:18 INFO 139924024543040] #quality_metric: host=algo-1, epoch=52, batch=0 train binary_f_1.000 <score>=0.761736049601\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:18 INFO 139924024543040] #quality_metric: host=algo-1, epoch=52, train binary_classification_accuracy <score>=0.742593406593\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:18 INFO 139924024543040] #quality_metric: host=algo-1, epoch=52, train binary_classification_cross_entropy <loss>=0.536330220317\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:18 INFO 139924024543040] #quality_metric: host=algo-1, epoch=52, train binary_f_1.000 <score>=0.774087147735\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 606.4298152923584, \"sum\": 606.4298152923584, \"min\": 606.4298152923584}}, \"EndTime\": 1545304578.794944, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304578.18808}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:18 INFO 139924024543040] #progress_metric: host=algo-1, completed 53 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 4824, \"sum\": 4824.0, \"min\": 4824}, \"Total Records Seen\": {\"count\": 1, \"max\": 4801210, \"sum\": 4801210.0, \"min\": 4801210}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 54, \"sum\": 54.0, \"min\": 54}}, \"EndTime\": 1545304578.795166, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 52}, \"StartTime\": 1545304578.188484}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:18 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=149257.44691 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:18.795] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 53, \"duration\": 605, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:18 INFO 139924024543040] #quality_metric: host=algo-1, epoch=53, batch=0 train binary_classification_accuracy <score>=0.731\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:18 INFO 139924024543040] #quality_metric: host=algo-1, epoch=53, batch=0 train binary_classification_cross_entropy <loss>=0.534813354492\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:18 INFO 139924024543040] #quality_metric: host=algo-1, epoch=53, batch=0 train binary_f_1.000 <score>=0.761736049601\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:19 INFO 139924024543040] #quality_metric: host=algo-1, epoch=53, train binary_classification_accuracy <score>=0.742758241758\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:19 INFO 139924024543040] #quality_metric: host=algo-1, epoch=53, train binary_classification_cross_entropy <loss>=0.535643682794\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:19 INFO 139924024543040] #quality_metric: host=algo-1, epoch=53, train binary_f_1.000 <score>=0.774212216789\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 561.8429183959961, \"sum\": 561.8429183959961, \"min\": 561.8429183959961}}, \"EndTime\": 1545304579.357311, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304578.795012}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:19 INFO 139924024543040] #progress_metric: host=algo-1, completed 54 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 4915, \"sum\": 4915.0, \"min\": 4915}, \"Total Records Seen\": {\"count\": 1, \"max\": 4891780, \"sum\": 4891780.0, \"min\": 4891780}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 55, \"sum\": 55.0, \"min\": 55}}, \"EndTime\": 1545304579.357509, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 53}, \"StartTime\": 1545304578.795439}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:19 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=161103.263973 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:19.357] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 54, \"duration\": 560, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:19 INFO 139924024543040] #quality_metric: host=algo-1, epoch=54, batch=0 train binary_classification_accuracy <score>=0.732\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:19 INFO 139924024543040] #quality_metric: host=algo-1, epoch=54, batch=0 train binary_classification_cross_entropy <loss>=0.534168945313\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:19 INFO 139924024543040] #quality_metric: host=algo-1, epoch=54, batch=0 train binary_f_1.000 <score>=0.762411347518\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:19 INFO 139924024543040] #quality_metric: host=algo-1, epoch=54, train binary_classification_accuracy <score>=0.742978021978\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:19 INFO 139924024543040] #quality_metric: host=algo-1, epoch=54, train binary_classification_cross_entropy <loss>=0.534974407825\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:19 INFO 139924024543040] #quality_metric: host=algo-1, epoch=54, train binary_f_1.000 <score>=0.774357242777\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 569.3109035491943, \"sum\": 569.3109035491943, \"min\": 569.3109035491943}}, \"EndTime\": 1545304579.927091, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304579.357375}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:19 INFO 139924024543040] #progress_metric: host=algo-1, completed 55 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 5006, \"sum\": 5006.0, \"min\": 5006}, \"Total Records Seen\": {\"count\": 1, \"max\": 4982350, \"sum\": 4982350.0, \"min\": 4982350}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 56, \"sum\": 56.0, \"min\": 56}}, \"EndTime\": 1545304579.927303, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 54}, \"StartTime\": 1545304579.357752}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:19 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=158989.320977 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:19.927] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 55, \"duration\": 568, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:19 INFO 139924024543040] #quality_metric: host=algo-1, epoch=55, batch=0 train binary_classification_accuracy <score>=0.731\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:19 INFO 139924024543040] #quality_metric: host=algo-1, epoch=55, batch=0 train binary_classification_cross_entropy <loss>=0.533539978027\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:19 INFO 139924024543040] #quality_metric: host=algo-1, epoch=55, batch=0 train binary_f_1.000 <score>=0.761313220941\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:20 INFO 139924024543040] #quality_metric: host=algo-1, epoch=55, train binary_classification_accuracy <score>=0.743142857143\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:20 INFO 139924024543040] #quality_metric: host=algo-1, epoch=55, train binary_classification_cross_entropy <loss>=0.534321731735\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:20 INFO 139924024543040] #quality_metric: host=algo-1, epoch=55, train binary_f_1.000 <score>=0.774425786528\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 577.2531032562256, \"sum\": 577.2531032562256, \"min\": 577.2531032562256}}, \"EndTime\": 1545304580.504873, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304579.927162}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:20 INFO 139924024543040] #progress_metric: host=algo-1, completed 56 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 5097, \"sum\": 5097.0, \"min\": 5097}, \"Total Records Seen\": {\"count\": 1, \"max\": 5072920, \"sum\": 5072920.0, \"min\": 5072920}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 57, \"sum\": 57.0, \"min\": 57}}, \"EndTime\": 1545304580.505189, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 55}, \"StartTime\": 1545304579.92753}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:20 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=156754.905333 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:20.505] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 56, \"duration\": 576, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:20 INFO 139924024543040] #quality_metric: host=algo-1, epoch=56, batch=0 train binary_classification_accuracy <score>=0.731\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:20 INFO 139924024543040] #quality_metric: host=algo-1, epoch=56, batch=0 train binary_classification_cross_entropy <loss>=0.53292590332\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:20 INFO 139924024543040] #quality_metric: host=algo-1, epoch=56, batch=0 train binary_f_1.000 <score>=0.760463045414\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:21 INFO 139924024543040] #quality_metric: host=algo-1, epoch=56, train binary_classification_accuracy <score>=0.743351648352\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:21 INFO 139924024543040] #quality_metric: host=algo-1, epoch=56, train binary_classification_cross_entropy <loss>=0.533685063624\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:21 INFO 139924024543040] #quality_metric: host=algo-1, epoch=56, train binary_f_1.000 <score>=0.774554756504\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 582.927942276001, \"sum\": 582.927942276001, \"min\": 582.927942276001}}, \"EndTime\": 1545304581.088537, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304580.504948}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:21 INFO 139924024543040] #progress_metric: host=algo-1, completed 57 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 5188, \"sum\": 5188.0, \"min\": 5188}, \"Total Records Seen\": {\"count\": 1, \"max\": 5163490, \"sum\": 5163490.0, \"min\": 5163490}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 58, \"sum\": 58.0, \"min\": 58}}, \"EndTime\": 1545304581.08875, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 56}, \"StartTime\": 1545304580.505581}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:21 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=155261.355303 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:21.088] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 57, \"duration\": 581, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:21 INFO 139924024543040] #quality_metric: host=algo-1, epoch=57, batch=0 train binary_classification_accuracy <score>=0.731\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:21 INFO 139924024543040] #quality_metric: host=algo-1, epoch=57, batch=0 train binary_classification_cross_entropy <loss>=0.532326293945\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:21 INFO 139924024543040] #quality_metric: host=algo-1, epoch=57, batch=0 train binary_f_1.000 <score>=0.760463045414\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:21 INFO 139924024543040] #quality_metric: host=algo-1, epoch=57, train binary_classification_accuracy <score>=0.743417582418\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:21 INFO 139924024543040] #quality_metric: host=algo-1, epoch=57, train binary_classification_cross_entropy <loss>=0.533063781738\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:21 INFO 139924024543040] #quality_metric: host=algo-1, epoch=57, train binary_f_1.000 <score>=0.774556093039\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 579.5390605926514, \"sum\": 579.5390605926514, \"min\": 579.5390605926514}}, \"EndTime\": 1545304581.668595, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304581.08859}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:21 INFO 139924024543040] #progress_metric: host=algo-1, completed 58 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 5279, \"sum\": 5279.0, \"min\": 5279}, \"Total Records Seen\": {\"count\": 1, \"max\": 5254060, \"sum\": 5254060.0, \"min\": 5254060}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 59, \"sum\": 59.0, \"min\": 59}}, \"EndTime\": 1545304581.668789, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 57}, \"StartTime\": 1545304581.089022}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:21 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=156188.835855 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:21.668] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 58, \"duration\": 578, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:21 INFO 139924024543040] #quality_metric: host=algo-1, epoch=58, batch=0 train binary_classification_accuracy <score>=0.732\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:21 INFO 139924024543040] #quality_metric: host=algo-1, epoch=58, batch=0 train binary_classification_cross_entropy <loss>=0.531740478516\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:21 INFO 139924024543040] #quality_metric: host=algo-1, epoch=58, batch=0 train binary_f_1.000 <score>=0.761140819964\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:22 INFO 139924024543040] #quality_metric: host=algo-1, epoch=58, train binary_classification_accuracy <score>=0.743538461538\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:22 INFO 139924024543040] #quality_metric: host=algo-1, epoch=58, train binary_classification_cross_entropy <loss>=0.532457337432\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:22 INFO 139924024543040] #quality_metric: host=algo-1, epoch=58, train binary_f_1.000 <score>=0.77460789616\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 613.0149364471436, \"sum\": 613.0149364471436, \"min\": 613.0149364471436}}, \"EndTime\": 1545304582.28207, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304581.668665}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:22 INFO 139924024543040] #progress_metric: host=algo-1, completed 59 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 5370, \"sum\": 5370.0, \"min\": 5370}, \"Total Records Seen\": {\"count\": 1, \"max\": 5344630, \"sum\": 5344630.0, \"min\": 5344630}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 60, \"sum\": 60.0, \"min\": 60}}, \"EndTime\": 1545304582.282276, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 58}, \"StartTime\": 1545304581.669027}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:22 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=147658.229935 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:22.282] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 59, \"duration\": 611, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:22 INFO 139924024543040] #quality_metric: host=algo-1, epoch=59, batch=0 train binary_classification_accuracy <score>=0.731\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:22 INFO 139924024543040] #quality_metric: host=algo-1, epoch=59, batch=0 train binary_classification_cross_entropy <loss>=0.531168029785\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:22 INFO 139924024543040] #quality_metric: host=algo-1, epoch=59, batch=0 train binary_f_1.000 <score>=0.760035682426\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:22 INFO 139924024543040] #quality_metric: host=algo-1, epoch=59, train binary_classification_accuracy <score>=0.743659340659\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:22 INFO 139924024543040] #quality_metric: host=algo-1, epoch=59, train binary_classification_cross_entropy <loss>=0.531865175017\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:22 INFO 139924024543040] #quality_metric: host=algo-1, epoch=59, train binary_f_1.000 <score>=0.77468149021\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 604.1219234466553, \"sum\": 604.1219234466553, \"min\": 604.1219234466553}}, \"EndTime\": 1545304582.886695, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304582.282136}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:22 INFO 139924024543040] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 5461, \"sum\": 5461.0, \"min\": 5461}, \"Total Records Seen\": {\"count\": 1, \"max\": 5435200, \"sum\": 5435200.0, \"min\": 5435200}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 61, \"sum\": 61.0, \"min\": 61}}, \"EndTime\": 1545304582.886887, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 59}, \"StartTime\": 1545304582.282544}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:22 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=149835.685304 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:22.887] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 60, \"duration\": 602, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:22 INFO 139924024543040] #quality_metric: host=algo-1, epoch=60, batch=0 train binary_classification_accuracy <score>=0.731\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:22 INFO 139924024543040] #quality_metric: host=algo-1, epoch=60, batch=0 train binary_classification_cross_entropy <loss>=0.530608520508\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:22 INFO 139924024543040] #quality_metric: host=algo-1, epoch=60, batch=0 train binary_f_1.000 <score>=0.760035682426\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:23 INFO 139924024543040] #quality_metric: host=algo-1, epoch=60, train binary_classification_accuracy <score>=0.743824175824\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:23 INFO 139924024543040] #quality_metric: host=algo-1, epoch=60, train binary_classification_cross_entropy <loss>=0.531286778712\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:23 INFO 139924024543040] #quality_metric: host=algo-1, epoch=60, train binary_f_1.000 <score>=0.77478069328\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 580.0271034240723, \"sum\": 580.0271034240723, \"min\": 580.0271034240723}}, \"EndTime\": 1545304583.467178, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304582.886758}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:23 INFO 139924024543040] #progress_metric: host=algo-1, completed 61 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 5552, \"sum\": 5552.0, \"min\": 5552}, \"Total Records Seen\": {\"count\": 1, \"max\": 5525770, \"sum\": 5525770.0, \"min\": 5525770}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 62, \"sum\": 62.0, \"min\": 62}}, \"EndTime\": 1545304583.4674, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 60}, \"StartTime\": 1545304582.887125}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:23 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=156050.76123 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:23.467] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 61, \"duration\": 578, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:23 INFO 139924024543040] #quality_metric: host=algo-1, epoch=61, batch=0 train binary_classification_accuracy <score>=0.731\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:23 INFO 139924024543040] #quality_metric: host=algo-1, epoch=61, batch=0 train binary_classification_cross_entropy <loss>=0.530061523438\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:23 INFO 139924024543040] #quality_metric: host=algo-1, epoch=61, batch=0 train binary_f_1.000 <score>=0.760035682426\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:24 INFO 139924024543040] #quality_metric: host=algo-1, epoch=61, train binary_classification_accuracy <score>=0.744\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:24 INFO 139924024543040] #quality_metric: host=algo-1, epoch=61, train binary_classification_cross_entropy <loss>=0.530721635756\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:24 INFO 139924024543040] #quality_metric: host=algo-1, epoch=61, train binary_f_1.000 <score>=0.774909175234\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 582.6029777526855, \"sum\": 582.6029777526855, \"min\": 582.6029777526855}}, \"EndTime\": 1545304584.050328, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304583.467246}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:24 INFO 139924024543040] #progress_metric: host=algo-1, completed 62 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 5643, \"sum\": 5643.0, \"min\": 5643}, \"Total Records Seen\": {\"count\": 1, \"max\": 5616340, \"sum\": 5616340.0, \"min\": 5616340}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 63, \"sum\": 63.0, \"min\": 63}}, \"EndTime\": 1545304584.05056, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 61}, \"StartTime\": 1545304583.467694}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:24 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=155343.639716 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:24.050] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 62, \"duration\": 581, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:24 INFO 139924024543040] #quality_metric: host=algo-1, epoch=62, batch=0 train binary_classification_accuracy <score>=0.731\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:24 INFO 139924024543040] #quality_metric: host=algo-1, epoch=62, batch=0 train binary_classification_cross_entropy <loss>=0.529526489258\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:24 INFO 139924024543040] #quality_metric: host=algo-1, epoch=62, batch=0 train binary_f_1.000 <score>=0.760035682426\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:24 INFO 139924024543040] #quality_metric: host=algo-1, epoch=62, train binary_classification_accuracy <score>=0.74410989011\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:24 INFO 139924024543040] #quality_metric: host=algo-1, epoch=62, train binary_classification_cross_entropy <loss>=0.530169263232\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:24 INFO 139924024543040] #quality_metric: host=algo-1, epoch=62, train binary_f_1.000 <score>=0.774997101225\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 563.8158321380615, \"sum\": 563.8158321380615, \"min\": 563.8158321380615}}, \"EndTime\": 1545304584.614684, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304584.050399}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:24 INFO 139924024543040] #progress_metric: host=algo-1, completed 63 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 5734, \"sum\": 5734.0, \"min\": 5734}, \"Total Records Seen\": {\"count\": 1, \"max\": 5706910, \"sum\": 5706910.0, \"min\": 5706910}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 64, \"sum\": 64.0, \"min\": 64}}, \"EndTime\": 1545304584.614889, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 62}, \"StartTime\": 1545304584.050839}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:24 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=160537.836236 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:24.615] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 63, \"duration\": 562, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:24 INFO 139924024543040] #quality_metric: host=algo-1, epoch=63, batch=0 train binary_classification_accuracy <score>=0.728\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:24 INFO 139924024543040] #quality_metric: host=algo-1, epoch=63, batch=0 train binary_classification_cross_entropy <loss>=0.529003173828\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:24 INFO 139924024543040] #quality_metric: host=algo-1, epoch=63, batch=0 train binary_f_1.000 <score>=0.757142857143\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:25 INFO 139924024543040] #quality_metric: host=algo-1, epoch=63, train binary_classification_accuracy <score>=0.744142857143\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:25 INFO 139924024543040] #quality_metric: host=algo-1, epoch=63, train binary_classification_cross_entropy <loss>=0.52962920103\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:25 INFO 139924024543040] #quality_metric: host=algo-1, epoch=63, train binary_f_1.000 <score>=0.774958680082\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 584.954023361206, \"sum\": 584.954023361206, \"min\": 584.954023361206}}, \"EndTime\": 1545304585.200107, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304584.614755}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:25 INFO 139924024543040] #progress_metric: host=algo-1, completed 64 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 5825, \"sum\": 5825.0, \"min\": 5825}, \"Total Records Seen\": {\"count\": 1, \"max\": 5797480, \"sum\": 5797480.0, \"min\": 5797480}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 65, \"sum\": 65.0, \"min\": 65}}, \"EndTime\": 1545304585.200341, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 63}, \"StartTime\": 1545304584.615125}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:25 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=154733.224909 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:25.200] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 64, \"duration\": 583, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:25 INFO 139924024543040] #quality_metric: host=algo-1, epoch=64, batch=0 train binary_classification_accuracy <score>=0.729\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:25 INFO 139924024543040] #quality_metric: host=algo-1, epoch=64, batch=0 train binary_classification_cross_entropy <loss>=0.528491088867\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:25 INFO 139924024543040] #quality_metric: host=algo-1, epoch=64, batch=0 train binary_f_1.000 <score>=0.758251561106\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[12/20/2018 11:16:25 INFO 139924024543040] #quality_metric: host=algo-1, epoch=64, train binary_classification_accuracy <score>=0.744241758242\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:25 INFO 139924024543040] #quality_metric: host=algo-1, epoch=64, train binary_classification_cross_entropy <loss>=0.529100989038\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:25 INFO 139924024543040] #quality_metric: host=algo-1, epoch=64, train binary_f_1.000 <score>=0.775021749638\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 579.5421600341797, \"sum\": 579.5421600341797, \"min\": 579.5421600341797}}, \"EndTime\": 1545304585.780154, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304585.200201}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:25 INFO 139924024543040] #progress_metric: host=algo-1, completed 65 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 5916, \"sum\": 5916.0, \"min\": 5916}, \"Total Records Seen\": {\"count\": 1, \"max\": 5888050, \"sum\": 5888050.0, \"min\": 5888050}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 66, \"sum\": 66.0, \"min\": 66}}, \"EndTime\": 1545304585.780356, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 64}, \"StartTime\": 1545304585.200584}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:25 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=156187.230426 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:25.780] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 65, \"duration\": 578, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:25 INFO 139924024543040] #quality_metric: host=algo-1, epoch=65, batch=0 train binary_classification_accuracy <score>=0.728\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:25 INFO 139924024543040] #quality_metric: host=algo-1, epoch=65, batch=0 train binary_classification_cross_entropy <loss>=0.527989746094\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:25 INFO 139924024543040] #quality_metric: host=algo-1, epoch=65, batch=0 train binary_f_1.000 <score>=0.757142857143\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:26 INFO 139924024543040] #quality_metric: host=algo-1, epoch=65, train binary_classification_accuracy <score>=0.744373626374\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:26 INFO 139924024543040] #quality_metric: host=algo-1, epoch=65, train binary_classification_cross_entropy <loss>=0.528584189279\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:26 INFO 139924024543040] #quality_metric: host=algo-1, epoch=65, train binary_f_1.000 <score>=0.775094266654\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 563.6389255523682, \"sum\": 563.6389255523682, \"min\": 563.6389255523682}}, \"EndTime\": 1545304586.344255, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304585.780221}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:26 INFO 139924024543040] #progress_metric: host=algo-1, completed 66 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 6007, \"sum\": 6007.0, \"min\": 6007}, \"Total Records Seen\": {\"count\": 1, \"max\": 5978620, \"sum\": 5978620.0, \"min\": 5978620}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 67, \"sum\": 67.0, \"min\": 67}}, \"EndTime\": 1545304586.344477, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 65}, \"StartTime\": 1545304585.78059}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:26 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=160582.218386 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:26.344] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 66, \"duration\": 562, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:26 INFO 139924024543040] #quality_metric: host=algo-1, epoch=66, batch=0 train binary_classification_accuracy <score>=0.727\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:26 INFO 139924024543040] #quality_metric: host=algo-1, epoch=66, batch=0 train binary_classification_cross_entropy <loss>=0.527498962402\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:26 INFO 139924024543040] #quality_metric: host=algo-1, epoch=66, batch=0 train binary_f_1.000 <score>=0.756467439786\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:26 INFO 139924024543040] #quality_metric: host=algo-1, epoch=66, train binary_classification_accuracy <score>=0.744538461538\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:26 INFO 139924024543040] #quality_metric: host=algo-1, epoch=66, train binary_classification_cross_entropy <loss>=0.528078388591\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:26 INFO 139924024543040] #quality_metric: host=algo-1, epoch=66, train binary_f_1.000 <score>=0.775206691486\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 601.2310981750488, \"sum\": 601.2310981750488, \"min\": 601.2310981750488}}, \"EndTime\": 1545304586.946015, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304586.344328}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:26 INFO 139924024543040] #progress_metric: host=algo-1, completed 67 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 6098, \"sum\": 6098.0, \"min\": 6098}, \"Total Records Seen\": {\"count\": 1, \"max\": 6069190, \"sum\": 6069190.0, \"min\": 6069190}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}}, \"EndTime\": 1545304586.946241, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 66}, \"StartTime\": 1545304586.344752}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:26 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=150546.287142 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:26.946] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 67, \"duration\": 600, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:26 INFO 139924024543040] #quality_metric: host=algo-1, epoch=67, batch=0 train binary_classification_accuracy <score>=0.727\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:26 INFO 139924024543040] #quality_metric: host=algo-1, epoch=67, batch=0 train binary_classification_cross_entropy <loss>=0.527018188477\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:26 INFO 139924024543040] #quality_metric: host=algo-1, epoch=67, batch=0 train binary_f_1.000 <score>=0.756467439786\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:27 INFO 139924024543040] #quality_metric: host=algo-1, epoch=67, train binary_classification_accuracy <score>=0.744703296703\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:27 INFO 139924024543040] #quality_metric: host=algo-1, epoch=67, train binary_classification_cross_entropy <loss>=0.527583177504\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:27 INFO 139924024543040] #quality_metric: host=algo-1, epoch=67, train binary_f_1.000 <score>=0.775340876124\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 612.1649742126465, \"sum\": 612.1649742126465, \"min\": 612.1649742126465}}, \"EndTime\": 1545304587.558694, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304586.94609}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:27 INFO 139924024543040] #progress_metric: host=algo-1, completed 68 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 6189, \"sum\": 6189.0, \"min\": 6189}, \"Total Records Seen\": {\"count\": 1, \"max\": 6159760, \"sum\": 6159760.0, \"min\": 6159760}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 69, \"sum\": 69.0, \"min\": 69}}, \"EndTime\": 1545304587.558929, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 67}, \"StartTime\": 1545304586.946498}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:27 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=147853.917549 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:27.559] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 68, \"duration\": 610, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:27 INFO 139924024543040] #quality_metric: host=algo-1, epoch=68, batch=0 train binary_classification_accuracy <score>=0.727\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:27 INFO 139924024543040] #quality_metric: host=algo-1, epoch=68, batch=0 train binary_classification_cross_entropy <loss>=0.526547180176\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:27 INFO 139924024543040] #quality_metric: host=algo-1, epoch=68, batch=0 train binary_f_1.000 <score>=0.756467439786\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:28 INFO 139924024543040] #quality_metric: host=algo-1, epoch=68, train binary_classification_accuracy <score>=0.744824175824\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:28 INFO 139924024543040] #quality_metric: host=algo-1, epoch=68, train binary_classification_cross_entropy <loss>=0.527098163311\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:28 INFO 139924024543040] #quality_metric: host=algo-1, epoch=68, train binary_f_1.000 <score>=0.775453763067\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 581.6879272460938, \"sum\": 581.6879272460938, \"min\": 581.6879272460938}}, \"EndTime\": 1545304588.140932, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304587.558767}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:28 INFO 139924024543040] #progress_metric: host=algo-1, completed 69 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 6280, \"sum\": 6280.0, \"min\": 6280}, \"Total Records Seen\": {\"count\": 1, \"max\": 6250330, \"sum\": 6250330.0, \"min\": 6250330}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 70, \"sum\": 70.0, \"min\": 70}}, \"EndTime\": 1545304588.141189, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 68}, \"StartTime\": 1545304587.559213}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:28 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=155591.845551 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:28.141] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 69, \"duration\": 580, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:28 INFO 139924024543040] #quality_metric: host=algo-1, epoch=69, batch=0 train binary_classification_accuracy <score>=0.727\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:28 INFO 139924024543040] #quality_metric: host=algo-1, epoch=69, batch=0 train binary_classification_cross_entropy <loss>=0.526085510254\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:28 INFO 139924024543040] #quality_metric: host=algo-1, epoch=69, batch=0 train binary_f_1.000 <score>=0.756467439786\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:28 INFO 139924024543040] #quality_metric: host=algo-1, epoch=69, train binary_classification_accuracy <score>=0.744835164835\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:28 INFO 139924024543040] #quality_metric: host=algo-1, epoch=69, train binary_classification_cross_entropy <loss>=0.526622952975\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:28 INFO 139924024543040] #quality_metric: host=algo-1, epoch=69, train binary_f_1.000 <score>=0.775443889985\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 605.1070690155029, \"sum\": 605.1070690155029, \"min\": 605.1070690155029}}, \"EndTime\": 1545304588.746623, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304588.141002}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:28 INFO 139924024543040] #progress_metric: host=algo-1, completed 70 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 6371, \"sum\": 6371.0, \"min\": 6371}, \"Total Records Seen\": {\"count\": 1, \"max\": 6340900, \"sum\": 6340900.0, \"min\": 6340900}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 71, \"sum\": 71.0, \"min\": 71}}, \"EndTime\": 1545304588.74683, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 69}, \"StartTime\": 1545304588.141488}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:28 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=149588.995727 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:28.747] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 70, \"duration\": 603, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:28 INFO 139924024543040] #quality_metric: host=algo-1, epoch=70, batch=0 train binary_classification_accuracy <score>=0.727\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:28 INFO 139924024543040] #quality_metric: host=algo-1, epoch=70, batch=0 train binary_classification_cross_entropy <loss>=0.52563293457\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:28 INFO 139924024543040] #quality_metric: host=algo-1, epoch=70, batch=0 train binary_f_1.000 <score>=0.756467439786\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:29 INFO 139924024543040] #quality_metric: host=algo-1, epoch=70, train binary_classification_accuracy <score>=0.744967032967\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:29 INFO 139924024543040] #quality_metric: host=algo-1, epoch=70, train binary_classification_cross_entropy <loss>=0.526157187326\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:29 INFO 139924024543040] #quality_metric: host=algo-1, epoch=70, train binary_f_1.000 <score>=0.775559939654\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 589.9600982666016, \"sum\": 589.9600982666016, \"min\": 589.9600982666016}}, \"EndTime\": 1545304589.337064, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304588.74669}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:29 INFO 139924024543040] #progress_metric: host=algo-1, completed 71 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 6462, \"sum\": 6462.0, \"min\": 6462}, \"Total Records Seen\": {\"count\": 1, \"max\": 6431470, \"sum\": 6431470.0, \"min\": 6431470}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}}, \"EndTime\": 1545304589.337257, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 70}, \"StartTime\": 1545304588.747076}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:29 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=153430.995202 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:29.337] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 71, \"duration\": 588, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:29 INFO 139924024543040] #quality_metric: host=algo-1, epoch=71, batch=0 train binary_classification_accuracy <score>=0.727\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:29 INFO 139924024543040] #quality_metric: host=algo-1, epoch=71, batch=0 train binary_classification_cross_entropy <loss>=0.525189025879\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:29 INFO 139924024543040] #quality_metric: host=algo-1, epoch=71, batch=0 train binary_f_1.000 <score>=0.756467439786\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:29 INFO 139924024543040] #quality_metric: host=algo-1, epoch=71, train binary_classification_accuracy <score>=0.745098901099\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:29 INFO 139924024543040] #quality_metric: host=algo-1, epoch=71, train binary_classification_cross_entropy <loss>=0.525700512561\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:29 INFO 139924024543040] #quality_metric: host=algo-1, epoch=71, train binary_f_1.000 <score>=0.775667311412\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 576.1969089508057, \"sum\": 576.1969089508057, \"min\": 576.1969089508057}}, \"EndTime\": 1545304589.91372, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304589.337128}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:29 INFO 139924024543040] #progress_metric: host=algo-1, completed 72 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 6553, \"sum\": 6553.0, \"min\": 6553}, \"Total Records Seen\": {\"count\": 1, \"max\": 6522040, \"sum\": 6522040.0, \"min\": 6522040}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 73, \"sum\": 73.0, \"min\": 73}}, \"EndTime\": 1545304589.9139, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 71}, \"StartTime\": 1545304589.337493}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:29 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=157094.974648 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:29.914] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 72, \"duration\": 574, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:29 INFO 139924024543040] #quality_metric: host=algo-1, epoch=72, batch=0 train binary_classification_accuracy <score>=0.729\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:29 INFO 139924024543040] #quality_metric: host=algo-1, epoch=72, batch=0 train binary_classification_cross_entropy <loss>=0.524753540039\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:29 INFO 139924024543040] #quality_metric: host=algo-1, epoch=72, batch=0 train binary_f_1.000 <score>=0.75781948168\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:30 INFO 139924024543040] #quality_metric: host=algo-1, epoch=72, train binary_classification_accuracy <score>=0.74532967033\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:30 INFO 139924024543040] #quality_metric: host=algo-1, epoch=72, train binary_classification_cross_entropy <loss>=0.525252572196\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:30 INFO 139924024543040] #quality_metric: host=algo-1, epoch=72, train binary_f_1.000 <score>=0.775846560079\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 560.3578090667725, \"sum\": 560.3578090667725, \"min\": 560.3578090667725}}, \"EndTime\": 1545304590.474554, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304589.913782}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:30 INFO 139924024543040] #progress_metric: host=algo-1, completed 73 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 6644, \"sum\": 6644.0, \"min\": 6644}, \"Total Records Seen\": {\"count\": 1, \"max\": 6612610, \"sum\": 6612610.0, \"min\": 6612610}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 74, \"sum\": 74.0, \"min\": 74}}, \"EndTime\": 1545304590.474757, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 72}, \"StartTime\": 1545304589.914168}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:30 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=161518.09106 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:30.474] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 73, \"duration\": 559, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:30 INFO 139924024543040] #quality_metric: host=algo-1, epoch=73, batch=0 train binary_classification_accuracy <score>=0.729\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:30 INFO 139924024543040] #quality_metric: host=algo-1, epoch=73, batch=0 train binary_classification_cross_entropy <loss>=0.524326049805\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:30 INFO 139924024543040] #quality_metric: host=algo-1, epoch=73, batch=0 train binary_f_1.000 <score>=0.75781948168\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:31 INFO 139924024543040] #quality_metric: host=algo-1, epoch=73, train binary_classification_accuracy <score>=0.745351648352\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:31 INFO 139924024543040] #quality_metric: host=algo-1, epoch=73, train binary_classification_cross_entropy <loss>=0.524813037914\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:31 INFO 139924024543040] #quality_metric: host=algo-1, epoch=73, train binary_f_1.000 <score>=0.775844223682\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 602.4858951568604, \"sum\": 602.4858951568604, \"min\": 602.4858951568604}}, \"EndTime\": 1545304591.077578, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304590.474618}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:31 INFO 139924024543040] #progress_metric: host=algo-1, completed 74 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 6735, \"sum\": 6735.0, \"min\": 6735}, \"Total Records Seen\": {\"count\": 1, \"max\": 6703180, \"sum\": 6703180.0, \"min\": 6703180}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 75, \"sum\": 75.0, \"min\": 75}}, \"EndTime\": 1545304591.077803, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 73}, \"StartTime\": 1545304590.475061}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:31 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=150233.119267 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:31.078] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 74, \"duration\": 601, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:31 INFO 139924024543040] #quality_metric: host=algo-1, epoch=74, batch=0 train binary_classification_accuracy <score>=0.729\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:31 INFO 139924024543040] #quality_metric: host=algo-1, epoch=74, batch=0 train binary_classification_cross_entropy <loss>=0.523906433105\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:31 INFO 139924024543040] #quality_metric: host=algo-1, epoch=74, batch=0 train binary_f_1.000 <score>=0.75781948168\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:31 INFO 139924024543040] #quality_metric: host=algo-1, epoch=74, train binary_classification_accuracy <score>=0.745494505495\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:31 INFO 139924024543040] #quality_metric: host=algo-1, epoch=74, train binary_classification_cross_entropy <loss>=0.524381574694\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:31 INFO 139924024543040] #quality_metric: host=algo-1, epoch=74, train binary_f_1.000 <score>=0.77592879257\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 585.3650569915771, \"sum\": 585.3650569915771, \"min\": 585.3650569915771}}, \"EndTime\": 1545304591.663463, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304591.077652}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:31 INFO 139924024543040] #progress_metric: host=algo-1, completed 75 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 6826, \"sum\": 6826.0, \"min\": 6826}, \"Total Records Seen\": {\"count\": 1, \"max\": 6793750, \"sum\": 6793750.0, \"min\": 6793750}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 76, \"sum\": 76.0, \"min\": 76}}, \"EndTime\": 1545304591.663663, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 74}, \"StartTime\": 1545304591.078067}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:31 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=154632.888871 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:31.663] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 75, \"duration\": 584, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:31 INFO 139924024543040] #quality_metric: host=algo-1, epoch=75, batch=0 train binary_classification_accuracy <score>=0.729\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:31 INFO 139924024543040] #quality_metric: host=algo-1, epoch=75, batch=0 train binary_classification_cross_entropy <loss>=0.52349420166\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:31 INFO 139924024543040] #quality_metric: host=algo-1, epoch=75, batch=0 train binary_f_1.000 <score>=0.75781948168\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:32 INFO 139924024543040] #quality_metric: host=algo-1, epoch=75, train binary_classification_accuracy <score>=0.745571428571\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:32 INFO 139924024543040] #quality_metric: host=algo-1, epoch=75, train binary_classification_cross_entropy <loss>=0.523957877358\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:32 INFO 139924024543040] #quality_metric: host=algo-1, epoch=75, train binary_f_1.000 <score>=0.77599001519\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 559.6599578857422, \"sum\": 559.6599578857422, \"min\": 559.6599578857422}}, \"EndTime\": 1545304592.223583, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304591.66353}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:32 INFO 139924024543040] #progress_metric: host=algo-1, completed 76 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 6917, \"sum\": 6917.0, \"min\": 6917}, \"Total Records Seen\": {\"count\": 1, \"max\": 6884320, \"sum\": 6884320.0, \"min\": 6884320}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 77, \"sum\": 77.0, \"min\": 77}}, \"EndTime\": 1545304592.22378, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 75}, \"StartTime\": 1545304591.663894}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:32 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=161733.261103 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:32.223] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 76, \"duration\": 558, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:32 INFO 139924024543040] #quality_metric: host=algo-1, epoch=76, batch=0 train binary_classification_accuracy <score>=0.729\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:32 INFO 139924024543040] #quality_metric: host=algo-1, epoch=76, batch=0 train binary_classification_cross_entropy <loss>=0.523089233398\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:32 INFO 139924024543040] #quality_metric: host=algo-1, epoch=76, batch=0 train binary_f_1.000 <score>=0.75781948168\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:32 INFO 139924024543040] #quality_metric: host=algo-1, epoch=76, train binary_classification_accuracy <score>=0.745725274725\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:32 INFO 139924024543040] #quality_metric: host=algo-1, epoch=76, train binary_classification_cross_entropy <loss>=0.523541631007\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:32 INFO 139924024543040] #quality_metric: host=algo-1, epoch=76, train binary_f_1.000 <score>=0.77614279495\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 634.9599361419678, \"sum\": 634.9599361419678, \"min\": 634.9599361419678}}, \"EndTime\": 1545304592.858997, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304592.223648}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:32 INFO 139924024543040] #progress_metric: host=algo-1, completed 77 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 7008, \"sum\": 7008.0, \"min\": 7008}, \"Total Records Seen\": {\"count\": 1, \"max\": 6974890, \"sum\": 6974890.0, \"min\": 6974890}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 78, \"sum\": 78.0, \"min\": 78}}, \"EndTime\": 1545304592.859196, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 76}, \"StartTime\": 1545304592.224008}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:32 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=142561.46306 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:32.859] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 77, \"duration\": 633, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:32 INFO 139924024543040] #quality_metric: host=algo-1, epoch=77, batch=0 train binary_classification_accuracy <score>=0.729\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:32 INFO 139924024543040] #quality_metric: host=algo-1, epoch=77, batch=0 train binary_classification_cross_entropy <loss>=0.522691162109\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:32 INFO 139924024543040] #quality_metric: host=algo-1, epoch=77, batch=0 train binary_f_1.000 <score>=0.75781948168\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:33 INFO 139924024543040] #quality_metric: host=algo-1, epoch=77, train binary_classification_accuracy <score>=0.745846153846\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:33 INFO 139924024543040] #quality_metric: host=algo-1, epoch=77, train binary_classification_cross_entropy <loss>=0.523132544549\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:33 INFO 139924024543040] #quality_metric: host=algo-1, epoch=77, train binary_f_1.000 <score>=0.776212408561\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 600.2018451690674, \"sum\": 600.2018451690674, \"min\": 600.2018451690674}}, \"EndTime\": 1545304593.459667, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304592.859061}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:33 INFO 139924024543040] #progress_metric: host=algo-1, completed 78 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 7099, \"sum\": 7099.0, \"min\": 7099}, \"Total Records Seen\": {\"count\": 1, \"max\": 7065460, \"sum\": 7065460.0, \"min\": 7065460}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 79, \"sum\": 79.0, \"min\": 79}}, \"EndTime\": 1545304593.459856, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 77}, \"StartTime\": 1545304592.859434}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:33 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=150813.508206 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:33.460] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 78, \"duration\": 598, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:33 INFO 139924024543040] #quality_metric: host=algo-1, epoch=78, batch=0 train binary_classification_accuracy <score>=0.729\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:33 INFO 139924024543040] #quality_metric: host=algo-1, epoch=78, batch=0 train binary_classification_cross_entropy <loss>=0.522299804688\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:33 INFO 139924024543040] #quality_metric: host=algo-1, epoch=78, batch=0 train binary_f_1.000 <score>=0.75781948168\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:34 INFO 139924024543040] #quality_metric: host=algo-1, epoch=78, train binary_classification_accuracy <score>=0.745978021978\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:34 INFO 139924024543040] #quality_metric: host=algo-1, epoch=78, train binary_classification_cross_entropy <loss>=0.522730332595\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:34 INFO 139924024543040] #quality_metric: host=algo-1, epoch=78, train binary_f_1.000 <score>=0.776302547031\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 591.3028717041016, \"sum\": 591.3028717041016, \"min\": 591.3028717041016}}, \"EndTime\": 1545304594.051479, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304593.459726}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:34 INFO 139924024543040] #progress_metric: host=algo-1, completed 79 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 7190, \"sum\": 7190.0, \"min\": 7190}, \"Total Records Seen\": {\"count\": 1, \"max\": 7156030, \"sum\": 7156030.0, \"min\": 7156030}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 80, \"sum\": 80.0, \"min\": 80}}, \"EndTime\": 1545304594.051699, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 78}, \"StartTime\": 1545304593.460147}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:34 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=153068.214688 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:34.051] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 79, \"duration\": 590, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:34 INFO 139924024543040] #quality_metric: host=algo-1, epoch=79, batch=0 train binary_classification_accuracy <score>=0.729\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:34 INFO 139924024543040] #quality_metric: host=algo-1, epoch=79, batch=0 train binary_classification_cross_entropy <loss>=0.521914794922\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:34 INFO 139924024543040] #quality_metric: host=algo-1, epoch=79, batch=0 train binary_f_1.000 <score>=0.75781948168\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:34 INFO 139924024543040] #quality_metric: host=algo-1, epoch=79, train binary_classification_accuracy <score>=0.745945054945\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:34 INFO 139924024543040] #quality_metric: host=algo-1, epoch=79, train binary_classification_cross_entropy <loss>=0.522334715791\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:34 INFO 139924024543040] #quality_metric: host=algo-1, epoch=79, train binary_f_1.000 <score>=0.776254028473\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 592.2501087188721, \"sum\": 592.2501087188721, \"min\": 592.2501087188721}}, \"EndTime\": 1545304594.64422, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304594.051561}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:34 INFO 139924024543040] #progress_metric: host=algo-1, completed 80 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 7281, \"sum\": 7281.0, \"min\": 7281}, \"Total Records Seen\": {\"count\": 1, \"max\": 7246600, \"sum\": 7246600.0, \"min\": 7246600}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 81, \"sum\": 81.0, \"min\": 81}}, \"EndTime\": 1545304594.644457, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 79}, \"StartTime\": 1545304594.051938}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:34 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=152824.361454 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:34.644] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 80, \"duration\": 591, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:34 INFO 139924024543040] #quality_metric: host=algo-1, epoch=80, batch=0 train binary_classification_accuracy <score>=0.729\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:34 INFO 139924024543040] #quality_metric: host=algo-1, epoch=80, batch=0 train binary_classification_cross_entropy <loss>=0.521535888672\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:34 INFO 139924024543040] #quality_metric: host=algo-1, epoch=80, batch=0 train binary_f_1.000 <score>=0.75781948168\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:35 INFO 139924024543040] #quality_metric: host=algo-1, epoch=80, train binary_classification_accuracy <score>=0.746142857143\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:35 INFO 139924024543040] #quality_metric: host=algo-1, epoch=80, train binary_classification_cross_entropy <loss>=0.521945422833\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:35 INFO 139924024543040] #quality_metric: host=algo-1, epoch=80, train binary_f_1.000 <score>=0.776415249562\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 586.1680507659912, \"sum\": 586.1680507659912, \"min\": 586.1680507659912}}, \"EndTime\": 1545304595.230937, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304594.644304}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:35 INFO 139924024543040] #progress_metric: host=algo-1, completed 81 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 7372, \"sum\": 7372.0, \"min\": 7372}, \"Total Records Seen\": {\"count\": 1, \"max\": 7337170, \"sum\": 7337170.0, \"min\": 7337170}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 82, \"sum\": 82.0, \"min\": 82}}, \"EndTime\": 1545304595.231179, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 80}, \"StartTime\": 1545304594.644737}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:35 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=154406.11729 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:35.231] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 81, \"duration\": 585, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:35 INFO 139924024543040] #quality_metric: host=algo-1, epoch=81, batch=0 train binary_classification_accuracy <score>=0.728\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:35 INFO 139924024543040] #quality_metric: host=algo-1, epoch=81, batch=0 train binary_classification_cross_entropy <loss>=0.521162841797\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:35 INFO 139924024543040] #quality_metric: host=algo-1, epoch=81, batch=0 train binary_f_1.000 <score>=0.757142857143\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[12/20/2018 11:16:35 INFO 139924024543040] #quality_metric: host=algo-1, epoch=81, train binary_classification_accuracy <score>=0.746307692308\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:35 INFO 139924024543040] #quality_metric: host=algo-1, epoch=81, train binary_classification_cross_entropy <loss>=0.521562185434\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:35 INFO 139924024543040] #quality_metric: host=algo-1, epoch=81, train binary_f_1.000 <score>=0.776545289119\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 588.4160995483398, \"sum\": 588.4160995483398, \"min\": 588.4160995483398}}, \"EndTime\": 1545304595.819903, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304595.231021}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:35 INFO 139924024543040] #progress_metric: host=algo-1, completed 82 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 7463, \"sum\": 7463.0, \"min\": 7463}, \"Total Records Seen\": {\"count\": 1, \"max\": 7427740, \"sum\": 7427740.0, \"min\": 7427740}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 83, \"sum\": 83.0, \"min\": 83}}, \"EndTime\": 1545304595.820106, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 81}, \"StartTime\": 1545304595.231456}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:35 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=153813.74519 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:35.820] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 82, \"duration\": 587, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:35 INFO 139924024543040] #quality_metric: host=algo-1, epoch=82, batch=0 train binary_classification_accuracy <score>=0.728\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:35 INFO 139924024543040] #quality_metric: host=algo-1, epoch=82, batch=0 train binary_classification_cross_entropy <loss>=0.520795532227\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:35 INFO 139924024543040] #quality_metric: host=algo-1, epoch=82, batch=0 train binary_f_1.000 <score>=0.757142857143\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:36 INFO 139924024543040] #quality_metric: host=algo-1, epoch=82, train binary_classification_accuracy <score>=0.746351648352\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:36 INFO 139924024543040] #quality_metric: host=algo-1, epoch=82, train binary_classification_cross_entropy <loss>=0.521184768509\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:36 INFO 139924024543040] #quality_metric: host=algo-1, epoch=82, train binary_f_1.000 <score>=0.776571030317\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 565.3560161590576, \"sum\": 565.3560161590576, \"min\": 565.3560161590576}}, \"EndTime\": 1545304596.385797, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304595.819967}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:36 INFO 139924024543040] #progress_metric: host=algo-1, completed 83 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 7554, \"sum\": 7554.0, \"min\": 7554}, \"Total Records Seen\": {\"count\": 1, \"max\": 7518310, \"sum\": 7518310.0, \"min\": 7518310}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 84, \"sum\": 84.0, \"min\": 84}}, \"EndTime\": 1545304596.386047, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 82}, \"StartTime\": 1545304595.820411}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:36 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=160084.363412 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:36.386] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 83, \"duration\": 564, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:36 INFO 139924024543040] #quality_metric: host=algo-1, epoch=83, batch=0 train binary_classification_accuracy <score>=0.728\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:36 INFO 139924024543040] #quality_metric: host=algo-1, epoch=83, batch=0 train binary_classification_cross_entropy <loss>=0.52043359375\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:36 INFO 139924024543040] #quality_metric: host=algo-1, epoch=83, batch=0 train binary_f_1.000 <score>=0.757142857143\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:36 INFO 139924024543040] #quality_metric: host=algo-1, epoch=83, train binary_classification_accuracy <score>=0.746395604396\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:36 INFO 139924024543040] #quality_metric: host=algo-1, epoch=83, train binary_classification_cross_entropy <loss>=0.520812918527\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:36 INFO 139924024543040] #quality_metric: host=algo-1, epoch=83, train binary_f_1.000 <score>=0.776583798017\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 580.5089473724365, \"sum\": 580.5089473724365, \"min\": 580.5089473724365}}, \"EndTime\": 1545304596.966873, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304596.385882}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:36 INFO 139924024543040] #progress_metric: host=algo-1, completed 84 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 7645, \"sum\": 7645.0, \"min\": 7645}, \"Total Records Seen\": {\"count\": 1, \"max\": 7608880, \"sum\": 7608880.0, \"min\": 7608880}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 85, \"sum\": 85.0, \"min\": 85}}, \"EndTime\": 1545304596.9671, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 83}, \"StartTime\": 1545304596.386334}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:36 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=155912.482574 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:36.967] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 84, \"duration\": 579, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:36 INFO 139924024543040] #quality_metric: host=algo-1, epoch=84, batch=0 train binary_classification_accuracy <score>=0.728\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:36 INFO 139924024543040] #quality_metric: host=algo-1, epoch=84, batch=0 train binary_classification_cross_entropy <loss>=0.520076843262\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:36 INFO 139924024543040] #quality_metric: host=algo-1, epoch=84, batch=0 train binary_f_1.000 <score>=0.757142857143\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:37 INFO 139924024543040] #quality_metric: host=algo-1, epoch=84, train binary_classification_accuracy <score>=0.746406593407\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:37 INFO 139924024543040] #quality_metric: host=algo-1, epoch=84, train binary_classification_cross_entropy <loss>=0.520446378603\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:37 INFO 139924024543040] #quality_metric: host=algo-1, epoch=84, train binary_f_1.000 <score>=0.776595641693\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 614.5381927490234, \"sum\": 614.5381927490234, \"min\": 614.5381927490234}}, \"EndTime\": 1545304597.581962, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304596.966947}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:37 INFO 139924024543040] #progress_metric: host=algo-1, completed 85 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 7736, \"sum\": 7736.0, \"min\": 7736}, \"Total Records Seen\": {\"count\": 1, \"max\": 7699450, \"sum\": 7699450.0, \"min\": 7699450}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 86, \"sum\": 86.0, \"min\": 86}}, \"EndTime\": 1545304597.582195, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 84}, \"StartTime\": 1545304596.967391}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:37 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=147285.020216 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:37.582] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 85, \"duration\": 613, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:37 INFO 139924024543040] #quality_metric: host=algo-1, epoch=85, batch=0 train binary_classification_accuracy <score>=0.728\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:37 INFO 139924024543040] #quality_metric: host=algo-1, epoch=85, batch=0 train binary_classification_cross_entropy <loss>=0.519725036621\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:37 INFO 139924024543040] #quality_metric: host=algo-1, epoch=85, batch=0 train binary_f_1.000 <score>=0.757575757576\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:38 INFO 139924024543040] #quality_metric: host=algo-1, epoch=85, train binary_classification_accuracy <score>=0.746483516484\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:38 INFO 139924024543040] #quality_metric: host=algo-1, epoch=85, train binary_classification_cross_entropy <loss>=0.520084941151\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:38 INFO 139924024543040] #quality_metric: host=algo-1, epoch=85, train binary_f_1.000 <score>=0.776643947022\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 583.3449363708496, \"sum\": 583.3449363708496, \"min\": 583.3449363708496}}, \"EndTime\": 1545304598.165839, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304597.582035}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:38 INFO 139924024543040] #progress_metric: host=algo-1, completed 86 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 7827, \"sum\": 7827.0, \"min\": 7827}, \"Total Records Seen\": {\"count\": 1, \"max\": 7790020, \"sum\": 7790020.0, \"min\": 7790020}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 87, \"sum\": 87.0, \"min\": 87}}, \"EndTime\": 1545304598.166071, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 85}, \"StartTime\": 1545304597.582464}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:38 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=155160.270016 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:38.166] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 86, \"duration\": 582, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:38 INFO 139924024543040] #quality_metric: host=algo-1, epoch=86, batch=0 train binary_classification_accuracy <score>=0.728\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:38 INFO 139924024543040] #quality_metric: host=algo-1, epoch=86, batch=0 train binary_classification_cross_entropy <loss>=0.519377929687\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:38 INFO 139924024543040] #quality_metric: host=algo-1, epoch=86, batch=0 train binary_f_1.000 <score>=0.757575757576\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:38 INFO 139924024543040] #quality_metric: host=algo-1, epoch=86, train binary_classification_accuracy <score>=0.74656043956\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:38 INFO 139924024543040] #quality_metric: host=algo-1, epoch=86, train binary_classification_cross_entropy <loss>=0.519728377793\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:38 INFO 139924024543040] #quality_metric: host=algo-1, epoch=86, train binary_f_1.000 <score>=0.776696585045\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 586.5380764007568, \"sum\": 586.5380764007568, \"min\": 586.5380764007568}}, \"EndTime\": 1545304598.752868, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304598.165925}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:38 INFO 139924024543040] #progress_metric: host=algo-1, completed 87 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 7918, \"sum\": 7918.0, \"min\": 7918}, \"Total Records Seen\": {\"count\": 1, \"max\": 7880590, \"sum\": 7880590.0, \"min\": 7880590}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 88, \"sum\": 88.0, \"min\": 88}}, \"EndTime\": 1545304598.753105, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 86}, \"StartTime\": 1545304598.1663}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:38 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=154310.905962 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:38.753] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 87, \"duration\": 585, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:38 INFO 139924024543040] #quality_metric: host=algo-1, epoch=87, batch=0 train binary_classification_accuracy <score>=0.729\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:38 INFO 139924024543040] #quality_metric: host=algo-1, epoch=87, batch=0 train binary_classification_cross_entropy <loss>=0.519035461426\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:38 INFO 139924024543040] #quality_metric: host=algo-1, epoch=87, batch=0 train binary_f_1.000 <score>=0.758251561106\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:39 INFO 139924024543040] #quality_metric: host=algo-1, epoch=87, train binary_classification_accuracy <score>=0.746703296703\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:39 INFO 139924024543040] #quality_metric: host=algo-1, epoch=87, train binary_classification_cross_entropy <loss>=0.519376463838\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:39 INFO 139924024543040] #quality_metric: host=algo-1, epoch=87, train binary_f_1.000 <score>=0.776828937686\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 570.235013961792, \"sum\": 570.235013961792, \"min\": 570.235013961792}}, \"EndTime\": 1545304599.323667, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304598.752947}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:39 INFO 139924024543040] #progress_metric: host=algo-1, completed 88 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 8009, \"sum\": 8009.0, \"min\": 8009}, \"Total Records Seen\": {\"count\": 1, \"max\": 7971160, \"sum\": 7971160.0, \"min\": 7971160}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 89, \"sum\": 89.0, \"min\": 89}}, \"EndTime\": 1545304599.323865, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 87}, \"StartTime\": 1545304598.753402}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:39 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=158734.610142 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:39.324] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 88, \"duration\": 568, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:39 INFO 139924024543040] #quality_metric: host=algo-1, epoch=88, batch=0 train binary_classification_accuracy <score>=0.73\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:39 INFO 139924024543040] #quality_metric: host=algo-1, epoch=88, batch=0 train binary_classification_cross_entropy <loss>=0.518697265625\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:39 INFO 139924024543040] #quality_metric: host=algo-1, epoch=88, batch=0 train binary_f_1.000 <score>=0.75935828877\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:39 INFO 139924024543040] #quality_metric: host=algo-1, epoch=88, train binary_classification_accuracy <score>=0.746978021978\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:39 INFO 139924024543040] #quality_metric: host=algo-1, epoch=88, train binary_classification_cross_entropy <loss>=0.519029002095\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:39 INFO 139924024543040] #quality_metric: host=algo-1, epoch=88, train binary_f_1.000 <score>=0.777099044503\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 604.9020290374756, \"sum\": 604.9020290374756, \"min\": 604.9020290374756}}, \"EndTime\": 1545304599.92903, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304599.32373}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:39 INFO 139924024543040] #progress_metric: host=algo-1, completed 89 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 8100, \"sum\": 8100.0, \"min\": 8100}, \"Total Records Seen\": {\"count\": 1, \"max\": 8061730, \"sum\": 8061730.0, \"min\": 8061730}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 90, \"sum\": 90.0, \"min\": 90}}, \"EndTime\": 1545304599.929233, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 88}, \"StartTime\": 1545304599.3241}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:39 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=149641.85253 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:39.929] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 89, \"duration\": 603, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:39 INFO 139924024543040] #quality_metric: host=algo-1, epoch=89, batch=0 train binary_classification_accuracy <score>=0.73\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:39 INFO 139924024543040] #quality_metric: host=algo-1, epoch=89, batch=0 train binary_classification_cross_entropy <loss>=0.518363220215\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:39 INFO 139924024543040] #quality_metric: host=algo-1, epoch=89, batch=0 train binary_f_1.000 <score>=0.75935828877\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:40 INFO 139924024543040] #quality_metric: host=algo-1, epoch=89, train binary_classification_accuracy <score>=0.747252747253\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:40 INFO 139924024543040] #quality_metric: host=algo-1, epoch=89, train binary_classification_cross_entropy <loss>=0.518685774583\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:40 INFO 139924024543040] #quality_metric: host=algo-1, epoch=89, train binary_f_1.000 <score>=0.777334598331\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 559.0090751647949, \"sum\": 559.0090751647949, \"min\": 559.0090751647949}}, \"EndTime\": 1545304600.488506, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304599.929094}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:40 INFO 139924024543040] #progress_metric: host=algo-1, completed 90 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 8191, \"sum\": 8191.0, \"min\": 8191}, \"Total Records Seen\": {\"count\": 1, \"max\": 8152300, \"sum\": 8152300.0, \"min\": 8152300}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}}, \"EndTime\": 1545304600.488711, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 89}, \"StartTime\": 1545304599.92947}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:40 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=161917.528243 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:40.488] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 90, \"duration\": 557, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:40 INFO 139924024543040] #quality_metric: host=algo-1, epoch=90, batch=0 train binary_classification_accuracy <score>=0.732\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:40 INFO 139924024543040] #quality_metric: host=algo-1, epoch=90, batch=0 train binary_classification_cross_entropy <loss>=0.518033081055\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:40 INFO 139924024543040] #quality_metric: host=algo-1, epoch=90, batch=0 train binary_f_1.000 <score>=0.761140819964\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:41 INFO 139924024543040] #quality_metric: host=algo-1, epoch=90, train binary_classification_accuracy <score>=0.747395604396\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:41 INFO 139924024543040] #quality_metric: host=algo-1, epoch=90, train binary_classification_cross_entropy <loss>=0.518346593836\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:41 INFO 139924024543040] #quality_metric: host=algo-1, epoch=90, train binary_f_1.000 <score>=0.777445370666\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 578.916072845459, \"sum\": 578.916072845459, \"min\": 578.916072845459}}, \"EndTime\": 1545304601.067899, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304600.488578}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:41 INFO 139924024543040] #progress_metric: host=algo-1, completed 91 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 8282, \"sum\": 8282.0, \"min\": 8282}, \"Total Records Seen\": {\"count\": 1, \"max\": 8242870, \"sum\": 8242870.0, \"min\": 8242870}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 92, \"sum\": 92.0, \"min\": 92}}, \"EndTime\": 1545304601.068106, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 90}, \"StartTime\": 1545304600.488954}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:41 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=156347.936916 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:41.068] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 91, \"duration\": 577, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:41 INFO 139924024543040] #quality_metric: host=algo-1, epoch=91, batch=0 train binary_classification_accuracy <score>=0.732\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:41 INFO 139924024543040] #quality_metric: host=algo-1, epoch=91, batch=0 train binary_classification_cross_entropy <loss>=0.517706787109\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:41 INFO 139924024543040] #quality_metric: host=algo-1, epoch=91, batch=0 train binary_f_1.000 <score>=0.761140819964\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:41 INFO 139924024543040] #quality_metric: host=algo-1, epoch=91, train binary_classification_accuracy <score>=0.747637362637\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:41 INFO 139924024543040] #quality_metric: host=algo-1, epoch=91, train binary_classification_cross_entropy <loss>=0.518011274736\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:41 INFO 139924024543040] #quality_metric: host=algo-1, epoch=91, train binary_f_1.000 <score>=0.777641146797\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 600.5880832672119, \"sum\": 600.5880832672119, \"min\": 600.5880832672119}}, \"EndTime\": 1545304601.66898, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304601.067969}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:41 INFO 139924024543040] #progress_metric: host=algo-1, completed 92 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 8373, \"sum\": 8373.0, \"min\": 8373}, \"Total Records Seen\": {\"count\": 1, \"max\": 8333440, \"sum\": 8333440.0, \"min\": 8333440}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 93, \"sum\": 93.0, \"min\": 93}}, \"EndTime\": 1545304601.66921, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 91}, \"StartTime\": 1545304601.068362}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:41 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=150706.589729 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:41.669] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 92, \"duration\": 599, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:41 INFO 139924024543040] #quality_metric: host=algo-1, epoch=92, batch=0 train binary_classification_accuracy <score>=0.732\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:41 INFO 139924024543040] #quality_metric: host=algo-1, epoch=92, batch=0 train binary_classification_cross_entropy <loss>=0.517384033203\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:41 INFO 139924024543040] #quality_metric: host=algo-1, epoch=92, batch=0 train binary_f_1.000 <score>=0.761140819964\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:42 INFO 139924024543040] #quality_metric: host=algo-1, epoch=92, train binary_classification_accuracy <score>=0.747901098901\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:42 INFO 139924024543040] #quality_metric: host=algo-1, epoch=92, train binary_classification_cross_entropy <loss>=0.517679620093\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:42 INFO 139924024543040] #quality_metric: host=algo-1, epoch=92, train binary_f_1.000 <score>=0.77785631978\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 572.019100189209, \"sum\": 572.019100189209, \"min\": 572.019100189209}}, \"EndTime\": 1545304602.24156, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304601.669057}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:42 INFO 139924024543040] #progress_metric: host=algo-1, completed 93 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 8464, \"sum\": 8464.0, \"min\": 8464}, \"Total Records Seen\": {\"count\": 1, \"max\": 8424010, \"sum\": 8424010.0, \"min\": 8424010}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 94, \"sum\": 94.0, \"min\": 94}}, \"EndTime\": 1545304602.241743, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 92}, \"StartTime\": 1545304601.6695}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:42 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=158229.869839 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:42.241] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 93, \"duration\": 570, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:42 INFO 139924024543040] #quality_metric: host=algo-1, epoch=93, batch=0 train binary_classification_accuracy <score>=0.732\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:42 INFO 139924024543040] #quality_metric: host=algo-1, epoch=93, batch=0 train binary_classification_cross_entropy <loss>=0.517064697266\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:42 INFO 139924024543040] #quality_metric: host=algo-1, epoch=93, batch=0 train binary_f_1.000 <score>=0.761140819964\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:42 INFO 139924024543040] #quality_metric: host=algo-1, epoch=93, train binary_classification_accuracy <score>=0.748120879121\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:42 INFO 139924024543040] #quality_metric: host=algo-1, epoch=93, train binary_classification_cross_entropy <loss>=0.517351451497\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:42 INFO 139924024543040] #quality_metric: host=algo-1, epoch=93, train binary_f_1.000 <score>=0.778058581457\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 650.7711410522461, \"sum\": 650.7711410522461, \"min\": 650.7711410522461}}, \"EndTime\": 1545304602.892824, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304602.241626}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:42 INFO 139924024543040] #progress_metric: host=algo-1, completed 94 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 8555, \"sum\": 8555.0, \"min\": 8555}, \"Total Records Seen\": {\"count\": 1, \"max\": 8514580, \"sum\": 8514580.0, \"min\": 8514580}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 95, \"sum\": 95.0, \"min\": 95}}, \"EndTime\": 1545304602.893093, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 93}, \"StartTime\": 1545304602.242022}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:42 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=139081.225069 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:42.893] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 94, \"duration\": 649, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:42 INFO 139924024543040] #quality_metric: host=algo-1, epoch=94, batch=0 train binary_classification_accuracy <score>=0.732\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:42 INFO 139924024543040] #quality_metric: host=algo-1, epoch=94, batch=0 train binary_classification_cross_entropy <loss>=0.516748535156\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:42 INFO 139924024543040] #quality_metric: host=algo-1, epoch=94, batch=0 train binary_f_1.000 <score>=0.761140819964\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:43 INFO 139924024543040] #quality_metric: host=algo-1, epoch=94, train binary_classification_accuracy <score>=0.74821978022\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:43 INFO 139924024543040] #quality_metric: host=algo-1, epoch=94, train binary_classification_cross_entropy <loss>=0.517026600597\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:43 INFO 139924024543040] #quality_metric: host=algo-1, epoch=94, train binary_f_1.000 <score>=0.778139282671\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 565.9208297729492, \"sum\": 565.9208297729492, \"min\": 565.9208297729492}}, \"EndTime\": 1545304603.459313, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304602.8929}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:43 INFO 139924024543040] #progress_metric: host=algo-1, completed 95 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 8646, \"sum\": 8646.0, \"min\": 8646}, \"Total Records Seen\": {\"count\": 1, \"max\": 8605150, \"sum\": 8605150.0, \"min\": 8605150}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 96, \"sum\": 96.0, \"min\": 96}}, \"EndTime\": 1545304603.459529, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 94}, \"StartTime\": 1545304602.893364}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:43 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=159938.847246 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:43.459] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 95, \"duration\": 564, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:43 INFO 139924024543040] #quality_metric: host=algo-1, epoch=95, batch=0 train binary_classification_accuracy <score>=0.733\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:43 INFO 139924024543040] #quality_metric: host=algo-1, epoch=95, batch=0 train binary_classification_cross_entropy <loss>=0.51643548584\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:43 INFO 139924024543040] #quality_metric: host=algo-1, epoch=95, batch=0 train binary_f_1.000 <score>=0.761819803747\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:44 INFO 139924024543040] #quality_metric: host=algo-1, epoch=95, train binary_classification_accuracy <score>=0.748461538462\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:44 INFO 139924024543040] #quality_metric: host=algo-1, epoch=95, train binary_classification_cross_entropy <loss>=0.516704893678\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:44 INFO 139924024543040] #quality_metric: host=algo-1, epoch=95, train binary_f_1.000 <score>=0.778335140998\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 609.9960803985596, \"sum\": 609.9960803985596, \"min\": 609.9960803985596}}, \"EndTime\": 1545304604.069789, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304603.459386}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:44 INFO 139924024543040] #progress_metric: host=algo-1, completed 96 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 8737, \"sum\": 8737.0, \"min\": 8737}, \"Total Records Seen\": {\"count\": 1, \"max\": 8695720, \"sum\": 8695720.0, \"min\": 8695720}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 97, \"sum\": 97.0, \"min\": 97}}, \"EndTime\": 1545304604.069992, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 95}, \"StartTime\": 1545304603.459764}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:44 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=148392.670363 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:44.070] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 96, \"duration\": 608, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:44 INFO 139924024543040] #quality_metric: host=algo-1, epoch=96, batch=0 train binary_classification_accuracy <score>=0.733\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:44 INFO 139924024543040] #quality_metric: host=algo-1, epoch=96, batch=0 train binary_classification_cross_entropy <loss>=0.516125366211\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:44 INFO 139924024543040] #quality_metric: host=algo-1, epoch=96, batch=0 train binary_f_1.000 <score>=0.761819803747\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:44 INFO 139924024543040] #quality_metric: host=algo-1, epoch=96, train binary_classification_accuracy <score>=0.748615384615\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:44 INFO 139924024543040] #quality_metric: host=algo-1, epoch=96, train binary_classification_cross_entropy <loss>=0.516386175805\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:44 INFO 139924024543040] #quality_metric: host=algo-1, epoch=96, train binary_f_1.000 <score>=0.778449261046\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 570.051908493042, \"sum\": 570.051908493042, \"min\": 570.051908493042}}, \"EndTime\": 1545304604.640303, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304604.069863}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:44 INFO 139924024543040] #progress_metric: host=algo-1, completed 97 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 8828, \"sum\": 8828.0, \"min\": 8828}, \"Total Records Seen\": {\"count\": 1, \"max\": 8786290, \"sum\": 8786290.0, \"min\": 8786290}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 98, \"sum\": 98.0, \"min\": 98}}, \"EndTime\": 1545304604.640533, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 96}, \"StartTime\": 1545304604.070221}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:44 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=158771.895413 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:44.640] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 97, \"duration\": 568, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:44 INFO 139924024543040] #quality_metric: host=algo-1, epoch=97, batch=0 train binary_classification_accuracy <score>=0.735\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:44 INFO 139924024543040] #quality_metric: host=algo-1, epoch=97, batch=0 train binary_classification_cross_entropy <loss>=0.515817993164\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:44 INFO 139924024543040] #quality_metric: host=algo-1, epoch=97, batch=0 train binary_f_1.000 <score>=0.764024933215\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:45 INFO 139924024543040] #quality_metric: host=algo-1, epoch=97, train binary_classification_accuracy <score>=0.748802197802\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:45 INFO 139924024543040] #quality_metric: host=algo-1, epoch=97, train binary_classification_cross_entropy <loss>=0.5160702793\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:45 INFO 139924024543040] #quality_metric: host=algo-1, epoch=97, train binary_f_1.000 <score>=0.778594605066\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 581.1660289764404, \"sum\": 581.1660289764404, \"min\": 581.1660289764404}}, \"EndTime\": 1545304605.222024, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304604.640378}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:45 INFO 139924024543040] #progress_metric: host=algo-1, completed 98 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 8919, \"sum\": 8919.0, \"min\": 8919}, \"Total Records Seen\": {\"count\": 1, \"max\": 8876860, \"sum\": 8876860.0, \"min\": 8876860}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 99, \"sum\": 99.0, \"min\": 99}}, \"EndTime\": 1545304605.22222, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 97}, \"StartTime\": 1545304604.640829}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:45 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=155750.242938 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:45.222] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 98, \"duration\": 580, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:45 INFO 139924024543040] #quality_metric: host=algo-1, epoch=98, batch=0 train binary_classification_accuracy <score>=0.735\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:45 INFO 139924024543040] #quality_metric: host=algo-1, epoch=98, batch=0 train binary_classification_cross_entropy <loss>=0.515513305664\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:45 INFO 139924024543040] #quality_metric: host=algo-1, epoch=98, batch=0 train binary_f_1.000 <score>=0.764024933215\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[12/20/2018 11:16:45 INFO 139924024543040] #quality_metric: host=algo-1, epoch=98, train binary_classification_accuracy <score>=0.748923076923\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:45 INFO 139924024543040] #quality_metric: host=algo-1, epoch=98, train binary_classification_cross_entropy <loss>=0.515757062304\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:45 INFO 139924024543040] #quality_metric: host=algo-1, epoch=98, train binary_f_1.000 <score>=0.778681855167\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 585.2870941162109, \"sum\": 585.2870941162109, \"min\": 585.2870941162109}}, \"EndTime\": 1545304605.807794, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304605.222088}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:45 INFO 139924024543040] #progress_metric: host=algo-1, completed 99 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 9010, \"sum\": 9010.0, \"min\": 9010}, \"Total Records Seen\": {\"count\": 1, \"max\": 8967430, \"sum\": 8967430.0, \"min\": 8967430}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 100, \"sum\": 100.0, \"min\": 100}}, \"EndTime\": 1545304605.808061, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 98}, \"StartTime\": 1545304605.222454}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:45 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=154616.713764 records/second\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:45.808] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 99, \"duration\": 584, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:45 INFO 139924024543040] #quality_metric: host=algo-1, epoch=99, batch=0 train binary_classification_accuracy <score>=0.735\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:45 INFO 139924024543040] #quality_metric: host=algo-1, epoch=99, batch=0 train binary_classification_cross_entropy <loss>=0.5152109375\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:45 INFO 139924024543040] #quality_metric: host=algo-1, epoch=99, batch=0 train binary_f_1.000 <score>=0.764024933215\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:46 INFO 139924024543040] #quality_metric: host=algo-1, epoch=99, train binary_classification_accuracy <score>=0.748923076923\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:46 INFO 139924024543040] #quality_metric: host=algo-1, epoch=99, train binary_classification_cross_entropy <loss>=0.515446364518\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:46 INFO 139924024543040] #quality_metric: host=algo-1, epoch=99, train binary_f_1.000 <score>=0.778681855167\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:46 INFO 139924024543040] #quality_metric: host=algo-1, train binary_classification_accuracy <score>=0.748923076923\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:46 INFO 139924024543040] #quality_metric: host=algo-1, train binary_classification_cross_entropy <loss>=0.515446364518\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:46 INFO 139924024543040] #quality_metric: host=algo-1, train binary_f_1.000 <score>=0.778681855167\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 577.8031349182129, \"sum\": 577.8031349182129, \"min\": 577.8031349182129}}, \"EndTime\": 1545304606.386276, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304605.807868}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:46 INFO 139924024543040] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Total Batches Seen\": {\"count\": 1, \"max\": 9101, \"sum\": 9101.0, \"min\": 9101}, \"Total Records Seen\": {\"count\": 1, \"max\": 9058000, \"sum\": 9058000.0, \"min\": 9058000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90570, \"sum\": 90570.0, \"min\": 90570}, \"Reset Count\": {\"count\": 1, \"max\": 101, \"sum\": 101.0, \"min\": 101}}, \"EndTime\": 1545304606.386468, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 99}, \"StartTime\": 1545304605.808444}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:46 INFO 139924024543040] #throughput_metric: host=algo-1, train throughput=156648.636649 records/second\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:46 WARNING 139924024543040] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:46 INFO 139924024543040] Pulling entire model from kvstore to finalize\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 2.415895462036133, \"sum\": 2.415895462036133, \"min\": 2.415895462036133}}, \"EndTime\": 1545304606.389147, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304606.386339}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:46 INFO 139924024543040] Saved checkpoint to \"/tmp/tmpakYZio/state-0001.params\"\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:46.396] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/test\", \"epoch\": 0, \"duration\": 59594, \"num_examples\": 1}\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 10, \"sum\": 10.0, \"min\": 10}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 10, \"sum\": 10.0, \"min\": 10}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 9430, \"sum\": 9430.0, \"min\": 9430}, \"Total Batches Seen\": {\"count\": 1, \"max\": 10, \"sum\": 10.0, \"min\": 10}, \"Total Records Seen\": {\"count\": 1, \"max\": 9430, \"sum\": 9430.0, \"min\": 9430}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 9430, \"sum\": 9430.0, \"min\": 9430}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1545304606.432905, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"test_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304606.396281}\n",
      "\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:46 INFO 139924024543040] #test_score (algo-1) : ('binary_classification_accuracy', 0.69575821845174979)\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:46 INFO 139924024543040] #test_score (algo-1) : ('binary_classification_cross_entropy', 0.57851394216430274)\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:46 INFO 139924024543040] #test_score (algo-1) : ('binary_f_1.000', 0.738920738920739)\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:46 INFO 139924024543040] #quality_metric: host=algo-1, test binary_classification_accuracy <score>=0.695758218452\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:46 INFO 139924024543040] #quality_metric: host=algo-1, test binary_classification_cross_entropy <loss>=0.578513942164\u001b[0m\n",
      "\u001b[31m[12/20/2018 11:16:46 INFO 139924024543040] #quality_metric: host=algo-1, test binary_f_1.000 <score>=0.738920738921\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:46.433] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/test\", \"epoch\": 1, \"duration\": 37, \"num_examples\": 10}\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:46.433] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/test\", \"duration\": 59631, \"num_epochs\": 2, \"num_examples\": 11}\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 59684.90409851074, \"sum\": 59684.90409851074, \"min\": 59684.90409851074}, \"setuptime\": {\"count\": 1, \"max\": 43.395042419433594, \"sum\": 43.395042419433594, \"min\": 43.395042419433594}}, \"EndTime\": 1545304606.433872, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1545304606.389203}\n",
      "\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:46.447] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"epoch\": 100, \"duration\": 637, \"num_examples\": 91}\u001b[0m\n",
      "\u001b[31m[2018-12-20 11:16:46.447] [tensorio] [info] data_pipeline_stats={\"name\": \"/opt/ml/input/data/train\", \"duration\": 59368, \"num_epochs\": 101, \"num_examples\": 9101}\u001b[0m\n",
      "\n",
      "2018-12-20 11:16:55 Uploading - Uploading generated training model\n",
      "2018-12-20 11:16:55 Completed - Training job completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Billable seconds: 100\n"
     ]
    }
   ],
   "source": [
    "fm.fit({'train': train_data, 'test': test_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [F1 score](https://en.wikipedia.org/wiki/F1_score) is a typical measure of success for a binary classifier:\n",
    "\n",
    "> In statistical analysis of binary classification, the F1 score (also F-score or F-measure) is a measure of a test's accuracy.\n",
    "\n",
    "With this set of hyperparameters, we've ended up with:\n",
    "\n",
    "    #quality_metric: host=algo-1, test binary_classification_accuracy <score>=0.697348886532\n",
    "    #quality_metric: host=algo-1, test binary_classification_cross_entropy <loss>=0.577387183342\n",
    "    #quality_metric: host=algo-1, test binary_f_1.000 <score>=0.743206766241\n",
    "    \n",
    "69% accuracy - not great!\n",
    "\n",
    "With the chosen thing we can tune:\n",
    "\n",
    "- bias_init_sigma\n",
    "- linear_init_sigma\n",
    "- factors_init_sigma\n",
    "\n",
    "\n",
    "    setting bias_init_sigma = 0.1 gave us test binary_classification_accuracy <score>=0.695758218452\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 9. Deploy a SageMaker endpoint with `deploy()`\n",
    "\n",
    "In the last section of this lab you will deploy a development endpoint and test run some inferences of your model. **Do not start this section unless your training job from the earlier step has status Completed.**\n",
    "\n",
    "The following will start up an endpoint instance. You can monitor progress through the notebook, or on the Amazon SageMaker console by choosing **Endpoints** in the menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: factorization-machines-2018-12-20-09-55-12-702\n",
      "INFO:sagemaker:Creating endpoint with name factorization-machines-2018-12-20-09-51-00-201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "fm_predictor = fm.deploy(instance_type='ml.c4.xlarge', initial_instance_count=1)\n",
    "\n",
    "\n",
    "fm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Configure serialization options for the predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fm_serializer(data):\n",
    "\n",
    "    js = {'instances': []}\n",
    "\n",
    "    for row in data:\n",
    "        js['instances'].append({'features': row.tolist()})\n",
    "\n",
    "    return json.dumps(js)\n",
    "\n",
    "# For example:\n",
    "# {\n",
    "#     \"instances\": [\n",
    "#         {\"features\": [1.5, 16.0, 14.0, 23.0]},\n",
    "#         {\"features\": [-2.0, 100.2, 15.2, 9.2]}\n",
    "#     ]\n",
    "# }\n",
    "\n",
    "fm_predictor.content_type = 'application/json'\n",
    "fm_predictor.serializer = fm_serializer\n",
    "\n",
    "# json_deserializer is in sagemaker.predictor\n",
    "fm_predictor.deserializer = json_deserializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D. Train & Deploy the Model\n",
    "\n",
    "\n",
    "\n",
    "## 11. Call the predictor\n",
    "Now you are ready to call the endpoint with 10 test inputs.\n",
    "\n",
    "The output of the cell will produce a text table with three columns:\n",
    "\n",
    "- **Prediction**\n",
    "- **Score** (from the model)\n",
    "- **Expected**\n",
    "\n",
    "If the model works well, Prediction and Expected values should match on each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction (Score) Expected\n",
      "      1.00   0.85     1.00\n",
      "      0.00   0.48     0.00\n",
      "      1.00   0.87     1.00\n",
      "      0.00   0.48     0.00\n",
      "      0.00   0.49     0.00\n",
      "      0.00   0.34     0.00\n",
      "      0.00   0.49     1.00\n",
      "      0.00   0.35     0.00\n",
      "      1.00   0.73     1.00\n",
      "      1.00   0.58     1.00\n"
     ]
    }
   ],
   "source": [
    "# Recall that test_features is our sparse matrix (not yet protobuf)\n",
    "result = fm_predictor.predict(test_features[1000:1010].toarray())\n",
    "\n",
    "def encodeFeatures(userId, nbUsers, nbMovies, movieId):\n",
    "\n",
    "    # nbRatingsTest, nbFeatures as lines, columns\n",
    "    # where nbFeatures = nbUsers+nbMovies\n",
    "    lines = 1\n",
    "    columns = nbUsers + nbMovies\n",
    "\n",
    "    lineNumber = 0\n",
    "    features = lil_matrix((lines, columns)).astype('float32')\n",
    "    features[lineNumber, int(userId) - 1] = 1\n",
    "    features[lineNumber, int(nbUsers) + int(movieId) - 1] = 1\n",
    "\n",
    "    return features\n",
    "\n",
    "def printPredictionWithExpectation(prediction, test_labels):\n",
    "    # Header\n",
    "    print(\"Prediction (Score) Expected\")\n",
    "\n",
    "    # Body\n",
    "    for index, p in enumerate(prediction['predictions']):\n",
    "        print(\"%10.2f %6.2f %8.2f\" %\n",
    "              (p['predicted_label'], p['score'], test_labels[1000 + index]))\n",
    "        \n",
    "printPredictionWithExpectation(result, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Check Some Recommendations\n",
    "### 12.1 Check we can get to Athena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyAthena in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (1.4.3)\n",
      "Requirement already satisfied: botocore>=1.5.52 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from PyAthena) (1.12.65)\n",
      "Requirement already satisfied: tenacity>=4.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from PyAthena) (5.0.2)\n",
      "Requirement already satisfied: future in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from PyAthena) (0.17.1)\n",
      "Requirement already satisfied: boto3>=1.4.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from PyAthena) (1.9.65)\n",
      "Requirement already satisfied: docutils>=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore>=1.5.52->PyAthena) (0.14)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore>=1.5.52->PyAthena) (2.7.3)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.20; python_version >= \"3.4\" in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore>=1.5.52->PyAthena) (1.22)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore>=1.5.52->PyAthena) (0.9.3)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tenacity>=4.1.0->PyAthena) (1.11.0)\n",
      "Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3>=1.4.4->PyAthena) (0.1.13)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install PyAthena"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.2 Check the favourite movies of a sample user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>movie_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>269</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>Santa Clause, The (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>269</td>\n",
       "      <td>167</td>\n",
       "      <td>1</td>\n",
       "      <td>Private Benjamin (1980)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>269</td>\n",
       "      <td>717</td>\n",
       "      <td>1</td>\n",
       "      <td>Juror, The (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>269</td>\n",
       "      <td>405</td>\n",
       "      <td>1</td>\n",
       "      <td>Mission: Impossible (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>269</td>\n",
       "      <td>940</td>\n",
       "      <td>1</td>\n",
       "      <td>Airheads (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>269</td>\n",
       "      <td>809</td>\n",
       "      <td>1</td>\n",
       "      <td>Rising Sun (1993)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>269</td>\n",
       "      <td>1478</td>\n",
       "      <td>1</td>\n",
       "      <td>Dead Presidents (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>269</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>Independence Day (ID4) (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>269</td>\n",
       "      <td>660</td>\n",
       "      <td>1</td>\n",
       "      <td>Fried Green Tomatoes (1991)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>269</td>\n",
       "      <td>234</td>\n",
       "      <td>1</td>\n",
       "      <td>Jaws (1975)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>269</td>\n",
       "      <td>196</td>\n",
       "      <td>1</td>\n",
       "      <td>Dead Poets Society (1989)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>269</td>\n",
       "      <td>393</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs. Doubtfire (1993)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>269</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>Striptease (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>269</td>\n",
       "      <td>1165</td>\n",
       "      <td>1</td>\n",
       "      <td>Big Bully (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>269</td>\n",
       "      <td>597</td>\n",
       "      <td>1</td>\n",
       "      <td>Eraser (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>269</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>Firm, The (1993)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>269</td>\n",
       "      <td>106</td>\n",
       "      <td>1</td>\n",
       "      <td>Diabolique (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>269</td>\n",
       "      <td>476</td>\n",
       "      <td>1</td>\n",
       "      <td>First Wives Club, The (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>269</td>\n",
       "      <td>281</td>\n",
       "      <td>1</td>\n",
       "      <td>River Wild, The (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>269</td>\n",
       "      <td>441</td>\n",
       "      <td>1</td>\n",
       "      <td>Amityville Horror, The (1979)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>269</td>\n",
       "      <td>710</td>\n",
       "      <td>1</td>\n",
       "      <td>Better Off Dead... (1985)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>269</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>Braveheart (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>269</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>Terminator 2: Judgment Day (1991)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>269</td>\n",
       "      <td>174</td>\n",
       "      <td>1</td>\n",
       "      <td>Raiders of the Lost Ark (1981)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>269</td>\n",
       "      <td>252</td>\n",
       "      <td>1</td>\n",
       "      <td>Lost World: Jurassic Park, The (1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>269</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>Forrest Gump (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>269</td>\n",
       "      <td>148</td>\n",
       "      <td>1</td>\n",
       "      <td>Ghost and the Darkness, The (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>269</td>\n",
       "      <td>210</td>\n",
       "      <td>1</td>\n",
       "      <td>Indiana Jones and the Last Crusade (1989)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>269</td>\n",
       "      <td>928</td>\n",
       "      <td>1</td>\n",
       "      <td>Craft, The (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>269</td>\n",
       "      <td>122</td>\n",
       "      <td>1</td>\n",
       "      <td>Cable Guy, The (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>269</td>\n",
       "      <td>56</td>\n",
       "      <td>5</td>\n",
       "      <td>Pulp Fiction (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>269</td>\n",
       "      <td>475</td>\n",
       "      <td>5</td>\n",
       "      <td>Trainspotting (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>269</td>\n",
       "      <td>644</td>\n",
       "      <td>5</td>\n",
       "      <td>Thin Blue Line, The (1988)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>269</td>\n",
       "      <td>276</td>\n",
       "      <td>5</td>\n",
       "      <td>Leaving Las Vegas (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>269</td>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>Hoop Dreams (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>269</td>\n",
       "      <td>428</td>\n",
       "      <td>5</td>\n",
       "      <td>Harold and Maude (1971)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>269</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>Fargo (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>269</td>\n",
       "      <td>529</td>\n",
       "      <td>5</td>\n",
       "      <td>My Life as a Dog (Mitt liv som hund) (1985)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>269</td>\n",
       "      <td>131</td>\n",
       "      <td>5</td>\n",
       "      <td>Breakfast at Tiffany's (1961)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>269</td>\n",
       "      <td>213</td>\n",
       "      <td>5</td>\n",
       "      <td>Room with a View, A (1986)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>269</td>\n",
       "      <td>175</td>\n",
       "      <td>5</td>\n",
       "      <td>Brazil (1985)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>269</td>\n",
       "      <td>1065</td>\n",
       "      <td>5</td>\n",
       "      <td>Koyaanisqatsi (1983)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>269</td>\n",
       "      <td>197</td>\n",
       "      <td>5</td>\n",
       "      <td>Graduate, The (1967)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>269</td>\n",
       "      <td>961</td>\n",
       "      <td>5</td>\n",
       "      <td>Orlando (1993)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>269</td>\n",
       "      <td>531</td>\n",
       "      <td>5</td>\n",
       "      <td>Shine (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>269</td>\n",
       "      <td>527</td>\n",
       "      <td>5</td>\n",
       "      <td>Gandhi (1982)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>269</td>\n",
       "      <td>238</td>\n",
       "      <td>5</td>\n",
       "      <td>Raising Arizona (1987)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>269</td>\n",
       "      <td>523</td>\n",
       "      <td>5</td>\n",
       "      <td>Cool Hand Luke (1967)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>269</td>\n",
       "      <td>506</td>\n",
       "      <td>5</td>\n",
       "      <td>Rebel Without a Cause (1955)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>269</td>\n",
       "      <td>640</td>\n",
       "      <td>5</td>\n",
       "      <td>Cook the Thief His Wife &amp; Her Lover, The (1989)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>269</td>\n",
       "      <td>194</td>\n",
       "      <td>5</td>\n",
       "      <td>Sting, The (1973)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>269</td>\n",
       "      <td>191</td>\n",
       "      <td>5</td>\n",
       "      <td>Amadeus (1984)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>269</td>\n",
       "      <td>537</td>\n",
       "      <td>5</td>\n",
       "      <td>My Own Private Idaho (1991)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>269</td>\n",
       "      <td>741</td>\n",
       "      <td>5</td>\n",
       "      <td>Last Supper, The (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>269</td>\n",
       "      <td>156</td>\n",
       "      <td>5</td>\n",
       "      <td>Reservoir Dogs (1992)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>269</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>Clerks (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>269</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>Taxi Driver (1976)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>269</td>\n",
       "      <td>512</td>\n",
       "      <td>5</td>\n",
       "      <td>Wings of Desire (1987)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>269</td>\n",
       "      <td>151</td>\n",
       "      <td>5</td>\n",
       "      <td>Willy Wonka and the Chocolate Factory (1971)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>269</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>Kids in the Hall: Brain Candy (1996)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>323 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id  movie_id  rating  \\\n",
       "0        269        63       1   \n",
       "1        269       167       1   \n",
       "2        269       717       1   \n",
       "3        269       405       1   \n",
       "4        269       940       1   \n",
       "5        269       809       1   \n",
       "6        269      1478       1   \n",
       "7        269       121       1   \n",
       "8        269       660       1   \n",
       "9        269       234       1   \n",
       "10       269       196       1   \n",
       "11       269       393       1   \n",
       "12       269       120       1   \n",
       "13       269      1165       1   \n",
       "14       269       597       1   \n",
       "15       269        77       1   \n",
       "16       269       106       1   \n",
       "17       269       476       1   \n",
       "18       269       281       1   \n",
       "19       269       441       1   \n",
       "20       269       710       1   \n",
       "21       269        22       1   \n",
       "22       269        96       1   \n",
       "23       269       174       1   \n",
       "24       269       252       1   \n",
       "25       269        69       1   \n",
       "26       269       148       1   \n",
       "27       269       210       1   \n",
       "28       269       928       1   \n",
       "29       269       122       1   \n",
       "..       ...       ...     ...   \n",
       "293      269        56       5   \n",
       "294      269       475       5   \n",
       "295      269       644       5   \n",
       "296      269       276       5   \n",
       "297      269        48       5   \n",
       "298      269       428       5   \n",
       "299      269       100       5   \n",
       "300      269       529       5   \n",
       "301      269       131       5   \n",
       "302      269       213       5   \n",
       "303      269       175       5   \n",
       "304      269      1065       5   \n",
       "305      269       197       5   \n",
       "306      269       961       5   \n",
       "307      269       531       5   \n",
       "308      269       527       5   \n",
       "309      269       238       5   \n",
       "310      269       523       5   \n",
       "311      269       506       5   \n",
       "312      269       640       5   \n",
       "313      269       194       5   \n",
       "314      269       191       5   \n",
       "315      269       537       5   \n",
       "316      269       741       5   \n",
       "317      269       156       5   \n",
       "318      269        42       5   \n",
       "319      269        23       5   \n",
       "320      269       512       5   \n",
       "321      269       151       5   \n",
       "322      269       108       5   \n",
       "\n",
       "                                          movie_name  \n",
       "0                           Santa Clause, The (1994)  \n",
       "1                            Private Benjamin (1980)  \n",
       "2                                  Juror, The (1996)  \n",
       "3                         Mission: Impossible (1996)  \n",
       "4                                    Airheads (1994)  \n",
       "5                                  Rising Sun (1993)  \n",
       "6                             Dead Presidents (1995)  \n",
       "7                      Independence Day (ID4) (1996)  \n",
       "8                        Fried Green Tomatoes (1991)  \n",
       "9                                        Jaws (1975)  \n",
       "10                         Dead Poets Society (1989)  \n",
       "11                             Mrs. Doubtfire (1993)  \n",
       "12                                 Striptease (1996)  \n",
       "13                                  Big Bully (1996)  \n",
       "14                                     Eraser (1996)  \n",
       "15                                  Firm, The (1993)  \n",
       "16                                 Diabolique (1996)  \n",
       "17                      First Wives Club, The (1996)  \n",
       "18                            River Wild, The (1994)  \n",
       "19                     Amityville Horror, The (1979)  \n",
       "20                         Better Off Dead... (1985)  \n",
       "21                                 Braveheart (1995)  \n",
       "22                 Terminator 2: Judgment Day (1991)  \n",
       "23                    Raiders of the Lost Ark (1981)  \n",
       "24             Lost World: Jurassic Park, The (1997)  \n",
       "25                               Forrest Gump (1994)  \n",
       "26                Ghost and the Darkness, The (1996)  \n",
       "27         Indiana Jones and the Last Crusade (1989)  \n",
       "28                                 Craft, The (1996)  \n",
       "29                             Cable Guy, The (1996)  \n",
       "..                                               ...  \n",
       "293                              Pulp Fiction (1994)  \n",
       "294                             Trainspotting (1996)  \n",
       "295                       Thin Blue Line, The (1988)  \n",
       "296                         Leaving Las Vegas (1995)  \n",
       "297                               Hoop Dreams (1994)  \n",
       "298                          Harold and Maude (1971)  \n",
       "299                                     Fargo (1996)  \n",
       "300      My Life as a Dog (Mitt liv som hund) (1985)  \n",
       "301                    Breakfast at Tiffany's (1961)  \n",
       "302                       Room with a View, A (1986)  \n",
       "303                                    Brazil (1985)  \n",
       "304                             Koyaanisqatsi (1983)  \n",
       "305                             Graduate, The (1967)  \n",
       "306                                   Orlando (1993)  \n",
       "307                                     Shine (1996)  \n",
       "308                                    Gandhi (1982)  \n",
       "309                           Raising Arizona (1987)  \n",
       "310                            Cool Hand Luke (1967)  \n",
       "311                     Rebel Without a Cause (1955)  \n",
       "312  Cook the Thief His Wife & Her Lover, The (1989)  \n",
       "313                                Sting, The (1973)  \n",
       "314                                   Amadeus (1984)  \n",
       "315                      My Own Private Idaho (1991)  \n",
       "316                          Last Supper, The (1995)  \n",
       "317                            Reservoir Dogs (1992)  \n",
       "318                                    Clerks (1994)  \n",
       "319                               Taxi Driver (1976)  \n",
       "320                           Wings of Desire (1987)  \n",
       "321     Willy Wonka and the Chocolate Factory (1971)  \n",
       "322             Kids in the Hall: Brain Candy (1996)  \n",
       "\n",
       "[323 rows x 4 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyathena import connect\n",
    "import pandas as pd\n",
    "conn = connect(s3_staging_dir='s3://pmj-ml-id-lab/sagemaker/recommender-fm/test/',\n",
    "               region_name='eu-west-1')\n",
    "\n",
    "df = pd.read_sql('select * from \"pmj-ml-lab-movielens\".\"user_ratings\" where user_id = 269 order by rating asc', conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  👍      💯\n",
      "                          Jaws   0.00     0.40\n",
      "                     Halloween   0.00     0.23\n",
      "       Nightmare on Elm Street   0.00     0.15\n",
      "                     Toy Story   0.00     0.30\n",
      "                          Babe   0.00     0.46\n",
      "          Natural Born Killers   0.00     0.33\n",
      "              The Great Escape   1.00     0.56\n",
      "The Good, The Bad and The Ugly   1.00     0.58\n"
     ]
    }
   ],
   "source": [
    "def printPrediction(prediction, movie):\n",
    "    for index, p in enumerate(prediction['predictions']):\n",
    "        print(\"%30s %6.2f %8.2f\" %\n",
    "              (movie['name'], p['predicted_label'], p['score']))\n",
    "\n",
    "def makeAndPrintPrediction(userId, movie):\n",
    "    encodedPrediction = encodeFeatures(userId, nbUsers, nbMovies, movie['id'])\n",
    "    prediction = fm_predictor.predict(encodedPrediction.toarray())\n",
    "    printPrediction(prediction, movie)\n",
    "\n",
    "\n",
    "movies = [\n",
    "    {\"id\": 234, \"name\": \"Jaws\"},\n",
    "    {\"id\": 834, \"name\": \"Halloween\"},\n",
    "    {\"id\": 219, \"name\": \"Nightmare on Elm Street\"},\n",
    "    {\"id\": 1, \"name\": \"Toy Story\"},\n",
    "    {\"id\": 8, \"name\": \"Babe\"},\n",
    "    {\"id\": 53, \"name\": \"Natural Born Killers\"},\n",
    "    {\"id\": 520, \"name\": \"The Great Escape\"},    \n",
    "    {\"id\": 177, \"name\": \"The Good, The Bad and The Ugly\"}        \n",
    "]\n",
    "\n",
    "scaredy_cat = 269\n",
    "\n",
    "print(\"%30s %4.5s %6.9s\" %\n",
    "      (\" \", \"👍\", \"💯\"))\n",
    "for movie in movies:\n",
    "    makeAndPrintPrediction(scaredy_cat, movie)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting endpoint with name: factorization-machines-2018-12-20-09-51-00-201\n"
     ]
    }
   ],
   "source": [
    "fm_predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
